消息队列的作用：1.应用解耦 2.流量消峰 3.消息分发 4.保证最终一致性

rocketMQ是使用java语言开发的，比起kafka的scala语言和rabbitMQ的erLang语言，更容易找到技术人员进行定制开发

四个角色：Producer、Consumer、Broker和NameServer，启动顺序是先启动NameServer后启动Broker

一个分布式消息队列中间件部署好以后，可以给很多业务提供服务，同一个服务也有不同类型的消息要投递，这些不同类型的消息以不同的Topic名称来区分，有了Topic之后还需要解决性能问题，如果一个Topic要发送和接收的数据量非常大，需要能支持增加并行处理的机器来提高处理速度，这时候一个Topic可以根据需求设置一个或多个Message Queue，类似于分区或Partition，Topic有了消息队列后可以并行地向各个Message Queue发送，消费者也可以并行地从多个Message Queue读取消息并消费，简单来说，topic是mq对业务的分类，Message Queue是技术上的分类

broker配置文件详解

1. namesrvAddr=192.168.100.131:9876; 192.168.100.132:9876 NameServer的地址，可以是多个

2.brokerClusterName=DefaultCluster Cluster的地址，如果集群机器数比较多，可以分成多个Cluster，每个Cluster供一个业务使用

3.brokerName=broker-a Broker的名称，Master和Slave通过使用相同的Broker名称来表明相互关系，以说明某个Slave是哪个Master的Slave

4.brokerId=0 一个Master Broker可以有多个Slave，0表示Master，大于0表示不同Slave的ID

5.fileReservedTime=48 在磁盘上保存消息的时长，单位是小时，自动删除超时的消息

6.deleteWhen=04 与fileReservedTime参数对应，表明在几点做消息删除动作，默认值04表示凌晨4点

7.brokerRole=SYNC_MASTER brokerRole有3种:SYNC_MASTER、ASYNC_MASTER、SLAVE。关键词SYNC和ASYNC表示Master和Slave之间同步消息的机制，SYNC的意思是当Slave和Master消息同步完成后，再返回发送成功的状态

8.flushDiskType=ASYNC_FLUSH 刷盘策略，分为SYNC和ASYNC，代表同步和异步刷盘，同步刷盘情况下，消息真正写入磁盘后再返回成功状态，异步刷盘情况下，消息写入page_cache后就返回成功状态

9.listenPort=10911 Broker监听的端口号，如果一台机器上启动了多个Broker，则要设置不同的端口号，避免冲突

10.storePathRootDir=/home/rmq/store-a 存储消息以及一些配置信息的根目录

这些配置参数，在Broker启动的时候生效，如果启动后有更改，要重启Broker

Consumer和Producer都必须设置GroupName、NameServer地址以及端口号，然后指明要操作的Topic名称，最后进入发送和接收逻辑

订阅组在提高系统的高可用性和吞吐量方面扮演着重要的角色，比如用Clustering模式消费一个Topic里的消息内容时，可以启动多个消费者并行消费，每个消费者只消费Topic里消息的一部分，以此提高消费速度，这个时候就是通过订阅组来指明哪些消费者是同一组，同一组的消费者共同消费同一个Topic里的内容

Topic的路由信息是指某个Topic所在的Broker相关信息，客户端可以通过NameServer来获取这些信息

一条消息被发送到RocketMQ后，默认会带上发送的时间戳，所以我们可以根据估计的时间来查询消息，指令是printMsg

根据使用者对读取操作的控制情况，消费者可分为两种类型，一个是DefaultMQPushConsumer由系统控制读取操作，收到消息后自动调用传入的处理方法来处理，另一个是DefaultMQPullConsumer读取操作中的大部分功能由使用者自主控制

DefaultMQPushConsumer需要设置三个参数，一个是这个Consumer的GroupName，二是NameServer的地址和端口号，三是Topic的名称

1.Consumer的GroupName用于把多个Consumer组织到一起，提高并发处理能力，GroupName需要和消息模式配合使用

RocketMQ支持两种消息模式：Clustering和Broadcasting

1.在Clustering模式下，同一个ConsumerGroup里的每个Consumer只消费所订阅消息的一部分内容，同一个组里所有的Consumer消费的内容合起来才是所订阅Topic内容的整体，从而达到负载均衡的目的

2.在Broadcasting模式下，同一个ConsumerGroup里的每个Consumer都能消费到所订阅Topic的全部消息，也就是一个消息会被多次分发，被多个Consumer消费

2.NameServer的地址和端口号，可以填写多个，用分号隔开，达到消除单点故障的目的

3.Topic名称用来标识消息类型，需要提前创建，如果不需要消费某个Topic下的所有消息，可以通过指定消息的tag进行消息过滤，比如：Consumer.subscribe("TopicTest", "tag1 || tag2 || tag3")，表示这个Consumer要消费TopicTest下带有tag1或tag2或tag3的消息

DefaultMQPushConsumer是通过长轮询的方式达到Push效果的方法

Push方式是Server端接收到消息后，主动把消息推送给Client端，实时性高，对于一个提供队列服务的Server来说，用Push方式主动推送有很多弊端，首先是加大Server端的工作量，进而影响Server的性能，其次，Client的处理能力各不相同，Client的状态不受Server控制，如果Client不能及时处理Server推送过来的消息，会造成各种潜在问题

Pull方式是Client端循环地从Server端拉取消息，主动权在Client手里，自己拉取到一定量消息后，处理妥当了再接着取，Pull方式的问题是循环拉取消息的间隔不好设定，间隔太短就处在一个忙等的状态，浪费资源，间隔太长，又不能及时处理消息

长轮询方式通过Client端和Server端的配合，达到既有Pull的优点，又能达到保证实时性的目的

Broker最长阻塞时间，默认设置是15秒，注意是Broker在没有新消息的时候才阻塞，有消息会立刻返回

服务端接收到新消费消息请求后，如果队列里没有新消息，并不急于返回，通过一个循环不断查看状态，每次waitForRunning一段时间（默认是5秒），然后再Check，默认情况下当Broker一直没有新消息，当第三次Check的时候，等待时间超过Request里面的Broker-SuspendMaxTimeMillis就返回空结果。在等待的过程中，Broker收到了新的消息后会直接调用notifyMessageArriving函数返回请求结果。长轮询的核心是，Broker端HOLD住客户端过来的请求一小段时间，在这个时间内有新消息到达，就利用现有的连接立刻返回消息给Consumer，长轮询的主动权还是掌握在Consumer手中，Broken即使有大量消息积压，也不会主动推送给Consumer，长轮询方式的局限性，是在HOLD住Consumer请求的时候需要占用资源，它适合用在消息队列这种客户端连接数可控的场景中

DefaultMQPushConsumer的流量控制

PushConsumer的核心还是Pull方式，所以采用这种方式的客户端能够根据自身的处理速度调整获取消息的操作速度，因为采用多线程处理方式实现，流量控制的方面比单线程要复杂得多

PushConsumer有个线程池，消息处理逻辑在各个线程里同时执行

Pull获得的消息，如果直接提交到线程池里执行，很难监控和控制，比如，如何得知当前消息堆积的数量？RocketMQ定义了一个快照类ProcessQueue来解决这些问题，在PushConsumer运行的时候，每个Message Queue都会有个对应的ProcessQueue对象，保存了这个Message Queue消息处理状态的快照

ProcessQueue对象里主要的内容是一个TreeMap和一个读写锁。TreeMap里以Message Queue的OffSet作为Key，以消息内容的引用为Value，保存了所有从MessageQueue获取到，但是还未被处理的消息，读写锁控制着多个线程对TreeMap对象的并发访问

PushConsumer会判断获取但还未处理的消息个数，消息总大小，Offset的跨度，任何一个值超过设定的大小就隔一段时间再拉取消息，从而达到流控的目的

DefaultMQPullConsumer

1.获取Message Queue并遍历

一个Topic包括多个Message Queue，如果这个Consumer需要获取Topic下所有的消息，就要遍历所有的Message Queue

2.维护OffsetStore

从一个Message Queue里拉取消息的时候，要传入OffSet参数，随着不断读取消息，OffSet会不断增长，这个时候由用户负责把OffSet存储下来

3.根据不同的消息状态做不同的处理

拉取消息的请求发出后，会返回FOUND、NO_MATCHED_MSG、NO_NEW_MSG、OFFSET_ILLEGAL四种状态，需要根据每个状态做不同的处理，比较重要的两个状态是FOUNT和NO_NEW_MSG，分别表示获取到消息和没有新的消息

Consumer的启动、关闭流程

对于PullConsumer来说，使用者主动权很高，可以根据实际需要暂停、停止、启动消费过程。需要注意的是OffSet的保存，要在程序的异常处理部分增加把OffSet写入磁盘方面的处理，记准了每个Message Queue的OffSet，才能保证消息消费的准确性

DefaultMQPushConsumer的退出，要调用shutdown()函数，以便释放资源、保存OffSet等，这个调用要加到Consumer所在应用的退出逻辑中。PushConsumer在启动时，会做各种配置检查，然后连接NameServer获取Topic信息，启动时如果遇到异常，比如无法连接NameServer，程序仍然可以正常启动不报错，DefaultMQPushConsumer会不断尝试重新连接

不同类型的生产者

生产者向消息队列里写入消息，不同的业务场景需要生产者采用不同的写入策略，比如同步发送、异步发送、延迟发送、发送事务消息等

1.DefaultMQProducer发送消息要经过五个步骤

1.设置Producer的GroupName 2.设置InstanceName，当一个JVM需要启动多个Producer的时候，通过设置不同的InstanceName来区分，不设置的话系统使用默认名称DEFAULT 3.设置发送失败重试次数，当网络出现异常的时候，这个次数影响消息的重复投递次数。4.设置NameServer地址 5.组装消息并发送

消息的发送有同步和异步两种方式，消息发送的返回状态有如下四种：FLUSH_DISK_TIMEOUT、FLUSH_SLAVE_TIMEOUT、SLAVE_NOT_AVAILABLE、SEND_OK，不同状态在不同的刷盘策略和同步策略的配置下含义是不同的。

FLUSH_DISK_TIMEOUT：表示没有在规定时间内完成刷盘（需要Broker的刷盘策略被设置成SYNC_FLUSH才会报这个错误）

FLUSH_SLAVE_TIMEOUT：表示在主备方式下，并且Broker被设置成SYNC_MASTER方式，没有在设定时间内完成主从同步

SLAVE_NOT_AVAILABLE：同上，但是没有找到被配置成slave的Broker

SEND_OK：没有发生上面列出的三个问题状态就是SEND_OK

写一个高质量的生产者程序，重点在于对发送结果的处理，要充分考虑各种异常，写清对应的处理逻辑

自定义消息发送规则：一个Topic会有多个Message Queue，如果使用Producer的默认配置，这个Producer会轮流向各个Message Queue发送消息。Consumer在消费消息的时候，会根据负载均衡策略，消费被分配到的Message Queue，如果不经过特定的设置，某条消息被发往哪个Message Queue，被哪个Consumer消费是未知的，发送消息的时候，把MessageQueueSelector的对象作为参数，根据传入的Object参数，或者根据Message消息内容确定把消息发往哪个Message Queue

RocketMQ的事务消息，是指发送消息事件和其他事件需要同时成功或同时失败，详细逻辑如下：

1.发送方向RocketMQ发送待确认消息 2.RocketMQ将收到的待确认消息持久化成功后，向发送方回复消息已经发送成功，此时第一阶段消息发送完成 3.发送方开始执行本地事件逻辑 4.发送方根据本地事件执行结果向RocketMQ发送二次确认(Commit或Rollback)消息，RocketMQ收到COMMIT状态则将第一阶段消息标记为可投递，订阅方将能够收到该消息，收到Rollback状态则删除第一阶段的消息，订阅方接收不到该消息 5.如果出现异常情况，步骤4提交的二次确认最终未到达RocketMQ，服务器在经过固定时间段后将对"待确认"消息发起回查请求 6.发送方收到消息回查请求后，通过检查对应消息的本地事件执行结果返回COMMIT或ROLLBACK状态 7.RocketMQ收到回查请求后，按照步骤4的逻辑处理

注意：由于事务消息会造成磁盘Cache的脏页过多，降低系统的性能，这部分功能已经在4.x版本中移除了

OffSet

实际运行中的系统，难免会遇到重新消费某条消息，跳过一段时间内的消息等情况，这些异常情况的处理，都和OffSet有关

RocketMQ中，一种类型的消息会放到一个Topic里，为了能够并行，一般一个Topic会有多个Message Queue，OffSet是指某个Topic下的一条消息在某个Message Queue里的位置，通过OffSet的值可以定位到这条消息，或者指示Consumer从这条消息开始向后继续处理

OffSet主要分为本地文件类型和Broker代存类型两种，对于CLUSTERING模式，也就是同一个Consumer group里的多个消费者每人消费一部分，各自收到的消息内容不一样，这种情况下，由Broker端存储和控制OffSet的值，使用RemoteBrokerOffSetStore结构

在BROADCASTING模式下，每个Consumer都收到这个Topic的全部消息，各个Consumer间相互没有干扰，RocketMQ使用LocalFileOffSetStore，把OffSet存到本地。

OffSetStore使用Json格式存储，例如：{"OffsetTable":{"brokerName":"localhost", "QueueId":1, "Topic":"broker1"}: 1}

在使用DefaultMQPushConsumer（CLUSTER模式）时，我们不用关心OffSetStore，如果是广播模式下，如果没有做持久化存储，可能因为程序的异常或重启而丢失OffSet

DefaultMQPushConsumer类里有个函数用来设置从哪儿开始消费消息。比如setConsumerFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET)，这个是从设置的offset开始读取，还可以设置从某个时间点开始消费消息，时间戳是精确到秒，但是设置读取位置不是每次都有效，它的优先级默认在上述讲的OffSet Store机制后面，大部分情况下这个设置在Consumer Group初次启动时有效，如果消费者正常运行后又被停止，然后再启动，会接着上次的OffSet开始消费

对于一个消息队列集群来说，系统由很多台机器组成，每个机器的角色、IP地址都不相同，而且这些信息是变动的。这种情况下，如果一个新的Producer或Consumer加入，怎么配置连接信息？NameServer的存在主要是为了解决这类问题，由NameServer维护这些配置信息、状态信息、其他角色都通过NameServer来协同执行

NameServer是整个消息队列中的状态服务器，集群的各个组件通过它来了解全局的信息，同时，各个角色的机器都要定期向NameServer上报自己的状态，超时不上报的话，NameServer会认为某个机器出故障不可用了，其他的组件会把这个机器从可用列表里移除

NameServer可以部署多个，相互之间独立，其他角色同时向多个NameServer机器上报状态信息，从而达到热备份的目的，NameServer本身是无状态的，也就是说NameServer中的Broker、Topic等状态信息不会持久化存储，都是由各个角色定时上报并存储到内存中的（NameServer支持配置化参数的持久化，一般用不到）

集群状态的存储，RouteInfoManager类中的5个属性

1.HashMap<String, List<QueueData>> topicQueueTable：key是topic的名称，value是个QueueData队列，队列的长度等于这个topic数据存储的Master Broke的个数，QueueData里存储着broker的名称、读写queue的数量、同步标识等

2. HashMap<String, BrokerData> brokerAddrTable：key是brokerName，相同名称的Broker可能存在多台机器，一个Master和多个Slave，所以value存储一个Master Broker和多个Slave Broker的地址信息

3.HashMap<String, Set<String, BrokerName>> clusterAddrTable：存储的是集群中Cluster的信息，就是一个Cluster名称对应一个由BrokerName组成的集合

4.HashMap<String, BrokerLiveInfo> brokerLiveTable：key表示一台机器，value存储这台机器的实时状态，包括上次更新状态的时间戳，NameServer会定期检查这个时间戳，超时没有更新就认为这个Broker无效了，将其从Broker列表里清除

5.HashMap<String, List<String>> filterServerTable：Filter Server是过滤服务器

NameServer的主要工作就是维护这五个变量中存储的信息

当NameServer和Broker的长连接断点以后，onChannelDestroy函数会被调用，把这个Broker的信息清理出去，NameServer还会每隔10秒钟检查一次Broker更新的时间戳，时间戳超过两分钟没有更新则认为Broker已失效，触发清理逻辑

创建Topic

创建命令可以指定在哪个Broker上创建本Topic的Message Queue或者在哪个Cluster下面所有的Master Broker上创建这个Topic的Message Queue，从而达到高可用性的目的，创建Topic的命令被发往对应的Broker，Broker接到创建Topic的请求后，执行具体的创建逻辑，执行完后向NameServer发送注册信息，NameServer完成创建Topic的逻辑后，其他客户端才能发现新增的Topic，NameServer首先更新Broker信息，然后对每个Master角色的Broker创建一个QueueData对象，如果是新建Topic，就是添加QueueData对象，如果是修改Topic，就是把旧的QueueData删除，加入新的QueueData

为何不用ZK？

ZK的功能很强大，包括自动Master选举等，RocketMQ的架构设计决定了它不需要进行Master选举，用不到这些复杂的功能，只需要一个轻量级的元数据服务器就足够了，中间件对稳定性要求很高，RocketMQ的NameServer只有很少的代码，容易维护，所以不需要再依赖另一个中间件，从而减少整体维护成本

RocketMQ自己定义了一个通信协议，使得模块间传输的二进制消息和有意义的内容之间互相转换

<- length -> <- header length -> <- header data -> <- body data ->

RocketMQ是基于Netty实现通信的

消息存储和发送

分布式队列因为有高可靠性的要求，所以数据要通过磁盘进行持久化存储。目前的高性能磁盘，顺序写速度可以达到600MB/s，超过了一般网卡的传输速度，但是磁盘随机写的速度只有大概100KB/s，因此好的消息队列系统会比普通的消息队列系统速度快多个数量级

Linux操作系统分为用户态和内核态，文件操作、网络操作需要涉及这两种形态的切换，免不了进行数据复制，一台服务器把本机磁盘文件的内容发送到客户端，一般分为两个步骤：

1.read（file, tmp_buf, len） 读取本地文件内容 2.write(socket, tmp_buf, len) 将读取的内容通过网络发送出去

tmp_buf是预先申请的内存，这两个看似简单的操作，实际进行了4次数据复制，分别是：从磁盘复制数据到内核态内存，从内核态内存复制到用户态内存，然后从用户态内存复制到网络驱动的内核态内存，最后是从网络驱动的内核态内存复制到网卡中进行传输。通过使用mmap的方式，可以省去向用户态的内存复制，提高速度。这种机制在Java中是通过MappedByteBuffer实现的，RocketMQ充分利用了上述特性，也就是所谓的“零拷贝”技术，提高消息存盘和网络发送的速度

因为操作系统的资源是有限的，如果访问资源的操作过多，必然会消耗过多的资源，而且如果不对这些操作加以区分，很可能造成资源访问的冲突。所以，为了减少有限资源的访问和使用冲突，Unix/Linux的设计哲学之一就是：对不同的操作赋予不同的执行等级，就是所谓特权的概念。简单说就是有多大能力做多大的事，与系统相关的一些特别关键的操作必须由最高特权的程序来完成。Intel的X86架构的CPU提供了0到3四个特权级，数字越小，特权越高，Linux操作系统中主要采用了0和3两个特权级，分别对应的就是内核态和用户态。运行于用户态的进程可以执行的操作和访问的资源都会受到极大的限制，而运行在内核态的进程则可以执行任何操作并且在资源的使用上没有限制。很多程序开始时运行于用户态，但在执行的过程中，一些操作需要在内核权限下才能执行，这就涉及到一个从用户态切换到内核态的过程。比如C函数库中的内存分配函数malloc()，它具体是使用sbrk()系统调用来分配内存，当malloc调用sbrk()的时候就涉及一次从用户态到内核态的切换，类似的函数还有printf()，调用的是wirte()系统调用来输出字符串，等等。

从宏观上来看，Linux操作系统的体系架构分为用户态和内核态（或者用户空间和内核）。内核从本质上看是一种软件——控制计算机的硬件资源，并提供上层应用程序运行的环境。用户态即上层应用程序的活动空间，应用程序的执行必须依托于内核提供的资源，包括CPU资源、存储资源、I/O资源等。为了使上层应用能够访问到这些资源，内核必须为上层应用提供访问的接口：即系统调用。系统调用是操作系统的最小功能单位，我们可以把系统调用看成是一种不能再化简的操作（类似于原子操作，但是不同概念），有人把它比作一个汉字的一个“笔画”，而一个“汉字”就代表一个上层应用，我觉得这个比喻非常贴切。因此，有时候如果要实现一个完整的汉字（给某个变量分配内存空间），就必须调用很多的系统调用。如果从实现者（程序员）的角度来看，这势必会加重程序员的负担，良好的程序设计方法是：重视上层的业务逻辑操作，而尽可能避免底层复杂的实现细节。库函数正是为了将程序员从复杂的细节中解脱出来而提出的一种有效方法。它实现对系统调用的封装，将简单的业务逻辑接口呈现给用户，方便用户调用，从这个角度上看，库函数就像是组成汉字的“偏旁”。这样的一种组成方式极大增强了程序设计的灵活性，对于简单的操作，我们可以直接调用系统调用来访问资源，如“人”，对于复杂操作，我们借助于库函数来实现，如“仁”。显然，这样的库函数依据不同的标准也可以有不同的实现版本，如ISO C 标准库，POSIX标准库等。

Shell是一个特殊的应用程序，俗称命令行，本质上是一个命令解释器，它下通系统调用，上通各种应用，通常充当着一种“胶水”的角色，来连接各个小功能程序，让不同程序能够以一个清晰的接口协同工作，从而增强各个程序的功能。同时，Shell是可编程的，它可以执行符合Shell语法的文本，这样的文本称为Shell脚本，通常短短的几行Shell脚本就可以实现一个非常大的功能，原因就是这些Shell语句通常都对系统调用做了一层封装。为了方便用户和系统交互，一般，一个Shell对应一个终端，终端是一个硬件设备，呈现给用户的是一个图形化窗口。我们可以通过这个窗口输入或者输出文本。这个文本直接传递给shell进行分析解释，然后执行

当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。

熟悉Unix/Linux系统的人都知道，fork的工作实际上是以系统调用的方式完成相应功能的，具体的工作是由sys_fork负责实施。其实无论是不是Unix或者Linux，对于任何操作系统来说，创建一个新的进程都是属于核心功能，因为它要做很多底层细致地工作，消耗系统的物理资源，比如分配物理内存，从父进程拷贝相关信息，拷贝设置页目录页表等等，这些显然不能随便让哪个程序就能去做，于是就自然引出特权级别的概念，显然，最关键性的权力必须由高特权级的程序来执行，这样才可以做到集中管理，减少有限资源的访问和使用冲突。

内核态与用户态程序执行的代码不同，执行时读取的数据地址也不相同，所以在切换时，需要把数据来回复制

RocketMQ消息存储

RocketMQ消息的存储是由ConsumeQueue和CommitLog配合完成的，消息真正的物理存储文件是CommitLog，ConsumeQueue是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储的地址。每个Topic下的每个Message Queue都有一个对应的ConsumeQueue文件。文件地址在\consumequeue\topicName\queueId\fileName

CommitLog以物理文件的方式存放，每台Broker上的CommitLog被本机器所有ConsumeQueue共享，文件地址：${user.home}\store\${commitLog}\${fileName}，在CommitLog中，一个消息的存储长度是不固定的，RocketMQ采取一些机制，尽量向CommitLog中顺序写，但是随机读

存储机制这样设计有以下几个好处：

1.CommitLog顺序写，可以大大提高写入效率

2.虽然是随机读，但是利用操作系统的pageCache机制，可以批量地从磁盘读取，作为cache存到内存中，加速后续的读取速度

3.为了保证完全的顺序写，需要ConsumeQueue这个中间结构，因为ConsumeQueue里只存偏移量信息，所以尺寸是有限的，在实际情况中，大部分的ConsumeQueue能够被全部读入内存，所有这个中间结构的操作速度很快，可以认为是内存读取的速度，此外为了保证CommitLog和ConsumeQueue的一致性，CommitLog里存储了Consume Queue、Message Key、Tag等所有信息，即使ConsumeQueue丢失，也可以通过commitLog完全恢复出来

RocketMQ分布式集群是通过Master和Slave的配合达到高可用性的，Master和Slave的区别：在Broker的配置文件中，参数brokerId的值为0表明这个Broker是Master，大于0表明这个Broker是Slave，同时BrokerRole参数也会说明这个Broker是Master还是Slave，Master角色的Broker支持读和写，Slave角色的Broker仅支持读，也就是Producer只能和Master角色的Broker连接写入消息，Consumer可以连接Master角色的Broker也可以连接Slave角色。

在Consumer的配置文件中，并不需要设置是从Master读还是从Slave读，当Master不可用或者繁忙的时候，Consumer会被自动切换到从Slave读，有了自动切换Consumer这种机制，当一个Master角色的机器出现故障后，Consumer仍然可以从Slave读取消息，这就达到了消费端的高可用性

如何达到发送端的高可用性？在创建Topic的时候，把Topic的多个Message Queue创建在多个Broker组上，这样当一个Broker组的Master不可用后，其他组的Master仍然可用，RocketMQ目前还不支持把Slave自动转成Master，如果需要可以手动停止Slave，更改配置文件后再启动

RocketMQ 的消息是存储到磁盘上的，这样既能保证断电后恢复，又可以让存储的消息 超出内存的限制 RocketMQ 为了提高性能，会尽可能地保证磁盘的顺序写 消息在通过 Producer 写人 RocketMQ 的时候，有两种写磁盘方式

异步刷盘方式：在返回写成功状态时 ，消息可能只是被写人了内存的PAGECACHE ，写操作的返回快，吞吐量大 ；当内存里的消息 积累到一定程度时 ，统一触发写磁盘动作，快速写人

同步刷盘方式：在返回写成功状态时，消息已经被写人磁盘 具体流程是，消息、写入内存的 PAGECACHE 后，立刻通知刷盘线程刷盘，然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写成功的状态

如果一个 Broker 组有 Master Slave, 消息需要从 Master 复制到 Slave上，有同步和异步两种复制方式 同步复制方式是 Master Slave 均写成功后才反馈给客户端写成功状态；异步复制方式是只要 Master 写成功即可反馈给客户端写成功状态

这两种复制方式各有优劣，在异步复制方式下，系统拥有较低的延迟和较高的吞吐量，但是如果 Master 出了故障，有些数据因为没有被写人 Slave ，有可能会丢失；在同步复制方式下，如果 Master 出故障， Slave 上有全部的备份数据，容易恢复，但是同步复制会增大数据写人延迟，降低系统吞吐量

实际应用中要结合业务场景，合理设置刷盘方式和主从复制方式，尤其是SYNC FLUSH 方式，由于频繁地触发磁盘写动作， 会明显降低性能。通常情况下，应该把 Master和Save 置成 ASYNC FLUSH 的刷盘方式，主从之间配置成 SYNC MASTER 的复制方式，这样即使有一台机器出故障， 仍然能保证数据不丢，是个不错的选择

顺序消息分为全局顺序消息和部分顺序消息，全局顺序消息指某个 Topic 下的所有消息都要保证顺序；部分顺序消息只要保证每一组消息被顺序消费即可

RocketMQ 在默认情况下不保证顺序，比如创建一个 Topic ，默认八个写队列，八个读队列。这时候一条消息可能被写入任意一个队列里；在数据的读取过程中，可能有多个 Consumer ，每个 Consumer 也可能启动多个线程并行处理，所以消息被哪个 Consumer 消费，被消费的顺序和写人的顺序是否一致是不确定的。

要保证全局顺序消息，需要先把 Topic 的读写队列数设置为一，然后Producer和Consumer 的并发设置也要是一。简单来说，为了保证整个Topic的全局消息有序，只能消除所有的并发处理，各部分都设置成单线程处理 这时高并发、高吞吐量的功能完全用不上了。

在实际应用中，更多的是像订单类消息那样，只需要部分有序即可。在这种情况下，我们经过合适的配置，依然可以利用 RocketMQ 高并发 、高吞吐量的能力

部分顺序消息

要保证部分消息有序，需要发送端和消费端配合处理。在发送端，要做到把同一业务ID的消息发送到同一个Message Queue，在消费过程中，要做到从同一个Message Queue读取的消息不被并发处理，这样才能达到部分有序

发送端使用 MessageQueueSelector 类来控制把消息发往哪个 MessageQueue，

消费端通过使用MessageListenerOrderly类来解决单 MessageQueue 的消息被并发处理的问题，

在MessageListenerOrderly的实现中，为每个 Consumer Queue 加个锁，消费每个消息前，需要先获得这个消息对应的 Consumer Queue 所对应的锁，这样保证了同一时间，同一个 Consumer Queue 的消息不被并发消 费，但不同 Consumer Queue 的消息可以并发处理

对分布式消息队列来说，同时做到确保一定投递和不重复投递是很难的，也就是所谓的“有且仅有一次” 在鱼和熊掌不可兼得的情况下， RocketMQ选择了确保一定投递，保证消息不丢失，但有可能造成消息重复。解决消息重复有两种方法：第一种方法是保证消费逻辑的幕等性（多次调用和一次调用效果相同）；另一种方法是维护一个巳消费消息的记录，消费前查询这个消息是否被消费过。这两种方法都需要使用者自己实现。

有四种方式可设置 NameServer 的地址， 下面按优先级由高到低依次介绍：

1 ）通过代码设置，比如在 Producer 中，通过 Producer.setNamesrv Addr(”name-server 1-ip:port;name-server2-ip：port”）来设置。在mqadmin 命令行工具中，是通过－n name-server-ipl :port;name-server- 2:port 参数来设置的，如果自定义了命令行工具，也可以通过 defaultMQAdminExt.setNamesrvAddr（” name-server-ip：port;name-server2-ip：port”）来设置

2）使用 Java 启动参数设置，对应的option是 rocketmq.namesrv.addr

3）通过 Linux 环境变量设置，在启动前设置变量： NAMESRV ADDR

4）通过 HTTP 服务来设置，当上述方法都没有使用，程序会向一个 HTTP地址发送请求来获取 NameServer 地址，默认的 URL是http://jmenv. tbsite.net: 8080/rocketmq/nsaddr 

第4种方式看似繁琐，但它是唯一支持动态增加 NameServer ，无须重启其他组件的方式。使用这种方式后其他组件会每隔2分钟请求一次该 URL ，获取最新的 NameServer 地址

只增加 Broker 不会对原有的 Topic 产生影响，原来创建好的 Topic 中数据的读写依然在原来的那些 Broker 上进行。

用Linux的kill pid 命令就可以正确地关闭 Broker, BrokerController 下有个shutdown 函数，这个函数被加到了 ShutdownHook 里，当用 Linux的kill命令时（不能用 kill -9 ), shutdown 函数会先被执行。也可以通过 RocketMQ 提供的工具（ mqshutdown broker ）来关闭 Broker ，它们的原理是一样的。

1) Broker 正常关闭，启动；

2) Broker 异常 Crash ，然后启动；

3) OS Crash ，重启；

4) 机器断电，但能马上恢复供电；

5）磁盘损坏；

6) CPU 主板、内存等关键设备损坏

第1种情况属于可控的软件问题，内存中的数据不会丢失。如果重启过程中有持续运行的 Consumer, Master机器出故障后， Consumer 会自动重连到对应的 Slave 机器，不会有消息丢失和偏差。当Master 角色的机器重启以后， Consumer 又会重新连接到 Master 机器（ 注意在启动 Master 机器的时候，如果 Consumer 正在从 Slave 消费消息，不要停止 Consumer。假如此时先停止Consumer 后再启动 Master 机器，然后再启动 Consumer ，这个时候 Consumer就会去读 Master 机器上已经滞后的 offset 值，造成消息大量重复）

如果第1种情况出现时有持续运行的 Producer，一台Master出故障后，Producer 只能向 Topic 下其他的 Master 机器发送消息，如果 Producer 采用同步发送方式，不会有消息丢失

第2、3、4种情况属于软件故障，内存的数据可能丢失，所 以刷盘策略不同，造成的影响也不同，如果 Master、Slave 都配置成 SYNC FLUSH ，可以达到和第1种情况相同的效果

第5、6种情况属于硬件故障 ，原有机器的磁盘数据可能会丢失。如果 Master 和 Slave 机器间配置成同步复制方式，某一台机器发生5或6的故障，也可以达到消息不丢失的效果。如果 Master 和 Slave机器间是异步复制，两次 Sync 间的消息会丢失

DefaultMQPushConsumer 默认的 pullBatchSize是32 ，也就是每次从某个MssageQueue 读取消息的时候，最多可以读 32 个

ConsumerQueue存储格式

<- commitLog OffSet -><- size -> <- message tag hashcode ->

通过tag过滤的过程就是对比定长的hashCode，经过hashCode对比，符合要求的消息被从CommitLog读取出来，消息在被消费前，会对比完整的Message Tag字符串，消除Hash冲突造成的误读

DefaultMQPushConsumer 的负载均衡

每个 DefaultMQPushConsumer 启动后，会马上会触发一个doRebalance 动作；而且在同一个ConsumerGroup 里加入新的 DefaultMQPushConsumer 时，各个 Consumer 都会被触发 do Rebalance 动作

具体的负载均衡算法有五种，默认用的是第一种AllocateMessageQueueAveragely。负载均衡的结果与 Topic的Message Queue数量，以及 ConsumerGroup 里的 Consumer 的数量有关。负载均衡的分配粒度只到 Message Queue ，把 Topic 下的所有 Message Queue 分配到不同的Consumer 中，所以 Message Queue和Consumer 的数量关系，或者整除关系影响负载均衡结果

以AllocateMessageQueueAveragely 策略为例，如果创建 Topic 的时候，把Message Queue 数设为3，当 Consumer数量为2的时候，有一个Consumer要处理 Topic 三分之二的消息，另一个处理三分之一的消息；当 Consumer数量为4的时候，有一个 Consumer无法收到消息，其他3个Consumer 各处理Topic 三分之一的消息。可见Message Queue数量设置过小不利于做负载均衡，通常情况下，应把一个 Topic的Message Queue 数设置为 16

编写程序消费RocketMQ消息的时候，最常用的类是DefaultMQPushConsumer，这个类让我们消费消息变得很简单

首先是初始化 MQClientinstance ，并且设置好 rebalance 策略和 pullApiWraper ，有这些结构后才能发送 pull 请求获取消息，然后是确定OffSetStore，OffsetStore里存储的是当前消费者所消费的消息在队列中的偏移量，根据消费消息方式的不同，offsetStore的类型也不同，如果是BROADCASTING广播模式，使用的是LocalFileOffetStore，Offset存到本地，如果是CLUSTERING模式，使用的是RemoteBrokerOffsetStore，Offset存到Broker机器上，然后是初始化consumeMessageService，根据对消息顺序需求的不同，使用不同的Service类型，最后调用MQClientInstance的START方法，开始获取数据。

首先通过判断未处理消息的个数和总大小来控制是否继续请求消息。对于顺序消息还有一些特殊判断逻辑。获取的消息返回后，根据返回状态，调用相应的处理方法

消息的处理结果可能有不同的值，主要的两个是CONSUME_SUCCESS和RECONSUME_LATER。如果消费不成功，要把消息提交到上面说的scheduledExecutorService线程池中，5秒后再执行，如果消费模式是CLUSTERING模式，未消费成功的消息会被先被发送回Broker，供这个ConsumerGroup里的其他Consumer消费，如果发送回Broker失败，再调用RECONSUME_LATER

MQClientinstance是客户端各种类型的Consumer和Producer的底层类，这个类首先从NameServer获取并保存各种配置信息，比如Topic的Route信息。同时 MQClientlnstance还会通过MQClientAPIImpl 类实现消息的收发，也就是从 Broker 获取消息或者发送消息到 Broker

Slave需要和Master同步的不只是消息本身，一些元数据信息也需要同步，比如TopicConfig信息、ConsumerOffset信息、DelayOffset和SubscriptionGroupConfig信息。 Broker在启动的时候，判断自己的角色是否是Slave ，是的话就启动定时同步任务

CommitLog的同步，CommitLog和元数据信息不同： 首先， CommitLog的数据量比元数据要大；其次 ，对实时性和可靠性要求也不一样。元数据信息是定时同步的，在两次同步的时间差里，如果出现异常可能会造成Master上的元数据内容和Slave上的元数据内容不一致，不过这种情况还可以补救。CommitLog 在高可靠性场景下如果没有及时同步， 一旦 Master机器出故障， 消息就彻底丢失，所以有专门的代码来实现Master和Slave之间消息体内容的同步。CommitLog同步的方式是直接基于JavaNIO来实现，而不是netty。

Netty 主要分为三部分：一是底层的零拷贝技术和统一通信模型；二是基于 JVM 实现的传输层； 三是常用协议支持






每个Broker与NameServer集群中的所有节点建立长连接，定时注册 Topic 信息到所有 NameServer

Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。

Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。

（1）CommitLog

消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容。单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件；

（2） ConsumeQueue

消息消费的逻辑队列，其中包含了这个MessageQueue在CommitLog中的起始物理位置偏移量offset，消息实体内容的大小和Message Tag的哈希值。从实际物理存储来说，ConsumeQueue对应每个Topic和QueuId下面的文件。单个文件大小约5.72M，每个文件由30W条数据组成，每个文件默认大小为600万个字节，当一个ConsumeQueue类型的文件写满了，则写入下一个文件；

（3）IndexFile

用于为生成的索引文件提供访问服务，通过消息Key值查询消息真正的实体内容。在实际的物理存储上，文件名则是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M，一个IndexFile可以保存 2000W个索引；

（4）MapedFileQueue

对连续物理存储的抽象封装类，源码中可以通过消息存储的物理偏移量位置快速定位该offset所在MappedFile(具体物理存储位置的抽象)、创建、删除MappedFile等操作；

（5）MappedFile

文件存储的直接内存映射业务抽象封装类，源码中通过操作该类，可以把消息字节写入PageCache缓存区（commit），或者原子性地将消息持久化的刷盘（flush）；

（1）消息生产与消息消费相互分离

Producer端发送消息最终写入的是CommitLog（消息存储的日志数据文件），Consumer端先从ConsumeQueue（消息逻辑队列）读取持久化消息的起始物理位置偏移量offset、大小size和消息Tag的HashCode值，随后再从CommitLog中进行读取待拉取消费消息的真正实体内容部分；而IndexFile（索引文件）则只是为了消息查询提供了一种通过key或时间区间来查询消息的方法（ps：这种通过IndexFile来查找消息的方法不影响发送与消费消息的主流程）。

（2）RocketMQ的CommitLog文件采用混合型存储

所有的Topic下的消息队列共用同一个CommitLog的日志数据文件，并通过建立类似索引文件—ConsumeQueue的方式来区分不同Topic下面的不同MessageQueue的消息，同时为消费消息起到一定的缓冲作用（只有ReputMessageService异步服务线程通过doDispatch异步生成了ConsumeQueue队列的元素后，Consumer端才能进行消费）。这样，只要消息写入并刷盘至CommitLog文件后，消息就不会丢失，即使ConsumeQueue中的数据丢失，也可以通过CommitLog来恢复。

（3）RocketMQ每次读写文件的时候真的是完全顺序读写么？

这里，发送消息时，生产者端的消息确实是顺序写入CommitLog；订阅消息时，消费者端也是顺序读取ConsumeQueue，然而根据其中的起始物理位置偏移量offset读取消息真实内容却是随机读取CommitLog。 在RocketMQ集群整体的吞吐量、并发量非常高的情况下，随机读取文件带来的性能开销影响还是比较大的，那么这里如何去优化和避免这个问题呢？后面的章节将会逐步来解答这个问题。

总结下RocketMQ存储架构的优缺点：

优点：

1、ConsumeQueue消息逻辑队列较为轻量级；

2、对磁盘的访问串行化，避免磁盘竟争，不会因为队列增加导致IOWAIT增高；

缺点：

1、对于CommitLog来说写入消息虽然是顺序写，但是读却变成了完全的随机读；

2、Consumer端订阅消费一条消息，需要先读ConsumeQueue，再读Commit Log，一定程度上增加了开销；

RocketMQ存储关键技术—Mmap与PageCache
（1）Mmap内存映射技术的特点

Mmap内存映射和普通标准IO操作的本质区别在于它并不需要将文件中的数据先拷贝至OS的内核IO缓冲区，而是可以直接将用户进程私有地址空间中的一块区域与文件对象建立映射关系，这样程序就好像可以直接从内存中完成对文件读/写操作一样。只有当缺页中断发生时，直接将文件从磁盘拷贝至用户态的进程空间内，只进行了一次数据拷贝。对于容量较大的文件来说（文件大小一般需要限制在1.5~2G以下，这也是CommitLog设置成1G的原因），采用Mmap的方式其读/写的效率和性能都非常高。

使用Mmap的限制

Mmap映射的内存空间释放的问题

由于映射的内存空间本身就不属于JVM的堆内存区（Java Heap），因此其不受JVM GC的控制，卸载这部分内存空间需要通过系统调用 unmap()方法来实现。然而unmap()方法是FileChannelImpl类里实现的私有方法，无法直接显示调用。RocketMQ中的做法是，通过Java反射的方式调用“sun.misc”包下的Cleaner类的clean()方法来释放映射占用的内存空间；

MappedByteBuffer内存映射大小限制

因为其占用的是虚拟内存（非JVM的堆内存），大小不受JVM的-Xmx参数限制，但其大小也受到OS虚拟内存大小的限制。一般来说，一次只能映射1.5~2G 的文件至用户态的虚拟内存空间，这也是为何RocketMQ默认设置单个CommitLog日志数据文件为1G的原因了；

使用MappedByteBuffe的其他问题

会存在内存占用率较高和文件关闭不确定性的问题；

OS的PageCache机制
PageCache是OS对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写访问，这里的主要原因就是在于OS使用PageCache机制对读写访问操作进行了性能优化，将一部分的内存用作PageCache。

（1）对于数据文件的读取

如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取（ps：顺序读入紧随其后的少数几个页面）。这样，只要下次访问的文件已经被加载至PageCache时，读取操作的速度基本等于访问内存。

（2）对于数据文件的写入

OS会先写入至Cache内，随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上。

对于文件的顺序读写操作来说，读和写的区域都在OS的PageCache内，此时读写性能接近于内存。RocketMQ的大致做法是，将数据文件映射到OS的虚拟内存中（通过JDK NIO的MappedByteBuffer），写消息的时候首先写入PageCache，并通过异步刷盘的方式将消息批量的做持久化（同时也支持同步刷盘）；订阅消费消息时（对CommitLog操作是随机读取），由于PageCache的局部性热点原理且整体情况下还是从旧到新的有序读，因此大部分情况下消息还是可以直接从Page Cache中读取，不会产生太多的缺页（Page Fault）中断而从磁盘读取。

（1）同步刷盘

只有在消息真正持久化至磁盘后，RocketMQ的Broker端才会真正地返回给Producer端一个成功的ACK响应。同步刷盘对MQ消息可靠性来说是一种不错的保障，但是性能上会有较大影响，一般适用于金融业务应用领域。RocketMQ同步刷盘的大致做法是，基于生产者消费者模型，主线程创建刷盘请求实例—GroupCommitRequest并在放入刷盘写队列后唤醒同步刷盘线程—GroupCommitService，来执行刷盘动作（其中用了CAS变量和CountDownLatch来保证线程间的同步）。这里，RocketMQ源码中用读写双缓存队列（requestsWrite/requestsRead）来实现读写分离，其带来的好处在于内部消费生成的同步刷盘请求可以不用加锁，提高并发度。

（2）异步刷盘

能够充分利用OS的PageCache的优势，只要消息写入PageCache即可将成功的ACK返回给Producer端。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了MQ的性能和吞吐量。异步和同步刷盘的区别在于，异步刷盘时，主线程并不会阻塞，在将刷盘线程wakeup后，就会继续执行。

同步复制和异步复制

当集群中有master和slave两个角色时，就要涉及到主从复制，同步复制是指在master刷盘后，需要在slave同步成功后才返回。而异步复制是在master刷盘成功后就直接返回。在高可用的角度去考虑，同步复制是不会在突然宕机时，丢失数据的。所以我们在工作中是使用同步复制异步刷盘的。

(1) NameServer： RocketMQ集群的命名服务器（也可以说是注册中心），它本身是无状态的（实际情况下可能存在每个NameServer实例上的数据有短暂的不一致现象，但是通过定时更新，在大部分情况下都是一致的），用于管理集群的元数据（ 例如，KV配置、Topic、Broker的注册信息）。nameserver存有全量的路由信息，提供对等的读写服务，支持快速扩缩容。nameserver接收client（producer/consumer）的请求，根据消息的topic获取相应的broker路由信息。集群部署后，节点之间无任何信息同步。

(2)Broker（Master）： RocketMQ消息代理服务器主节点，起到串联Producer的消息发送和Consumer的消息消费，和将消息的落盘存储的作用；

(3)Broker（Slave）： RocketMQ消息代理服务器备份节点，主要是通过同步/异步的方式(同步复制：消息发给master的同时也会将消息发送给slave 异步双写：只发送到master，再由master异步同步到slave)将主节点的消息同步过来进行备份，为RocketMQ集群的高可用性提供保障；

(4)queue（队列）: queue是消息的物理管理单位，而topic是逻辑管理单位。一个topic下可以有多个queue，默认自动创建是4个，手动创建是8个。queue的引入使得消息存储可以分布式集群化，具有了水平扩展的能力。1个message只能属于1个queue、1个topic。在rocketmq中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是指队列中的每个存储单元都是定长，访问其中的存储单元使用offset来访问，offset 为 java long 类型，64 位，理论上在 100年内不会溢出，所以认为是长度无限，另外队列中只保存最近几天的数据，之前的数据会按照过期时间来删除。也可以认为 Message Queue是一个长度无限的数组，offset就是下标。

rocketmq中，producer将消息发送给broker时，需要指定发送到哪一个queue中，默认情况下，producer会轮询的将消息发送到每个queue中，顺序是随机的，但总体上每个queue的消息数量均分，所有broker下的queue合并成一个list去轮询,也可以由程序员通过MessageQueueSelector接口来指定具体发送到哪个queue中。

对于consumer而言，会为每个consumer分配固定的队列（如果队列总数没有发生变化），consumer从固定的队列中去拉取没有消费的消息进行处理。消费端会通过RebalanceService线程，10秒钟做一次基于topic下的所有队列负载，获取同一个Consumer Group下的所有Consumer实例数或Topic的queue的个数是否改变，通知所有Consumer实例重新做一次负载均衡算法。

(1)NamerServer和NamerServer： nameserver互相独立，彼此没有通信关系，单台nameserver挂掉，不影响其他nameserver。

(2)Broker和NamerServer： Broker（Master or Slave）均会和每一个NameServer实例来建立TCP连接，定时注册topic&broker的路由信息到所有name server中。Broker在启动的时候会注册自己配置的Topic信息到NameServer集群的每一台机器中。即每一个NameServer均有该broker的Topic路由配置信息。其中，Master与Master之间无连接，Master与Slave之间有连接；

(2)Producer、Consumer与NamerServer： 每一个Producer会与NameServer集群中的一个实例建立TCP连接，从这个NameServer实例上拉取Topic路由信息；如果该nameserver挂掉，消费者会自动连接下一个nameserver，直到有可用连接为止，并能自动重连。

(3)Producer、Consumer和Broker: Producer会和它要发送的topic相关联的Master的Broker代理服务器建立TCP连接，用于发送消息以及定时的心跳信息；集群消费模式下，一个消费者集群多台机器共同消费一个topic的多个队列，一个队列只会被一个消费者消费。如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。

（1）Pull模式的Consumer端代码如下

在示例代码中，可以看到业务工程在Consumer启动后，Consumer主动获取MessageQueue的Set集合，遍历该集合中的每一个队列，发送Pull的请求（参数中带有队列中的消息偏移量），同时需要Consumer端自己保存消息消费的offset偏移量至本地变量中。在Pull模式下，需要业务应用代码自身去完成比较多的事情，因此在实际应用中用的较少。

（2）Push模式的Consumer端代码如下

在示例代码中，业务工程的应用程序使用Push方式进行消费时，Consumer端注册了一个监听器，Consumer在收到消息后主动调用这个监听器完成消费并进行对应的业务逻辑处理。由此可见，业务应用代码只需要完成消息消费即可，无需参与MQ本身的一些任务处理

消费者核心类

RebalanceImpl
字面上的意思（重新平衡）也就是消费端消费者与消息队列的重新分布，与消息应该分配给哪个消费者消费息息相关。负责分配当前 Consumer 可消费的消息队列( MessageQueue )。当有新的 Consumer 的加入或移除，都会重新分配消息队列。启动MQClientInstance实例时候，会完成负载均衡服务线程—RebalanceService的启动（每隔20s执行一次）。

Rebalance是针对Topic+ConsumerGroup进行Rebalance的，在我们创建的comsumer过程中会订阅topic（包括%retry%consumerGroup），Rebalance就是要这些Topic下的所有messageQueue按照一定的规则分发给consumerGroup下的consumer进行消费。

RocketMQ消息重试

producer发送消息重试

同步发送，除了正常调用一次，发送消息如果失败了会重试2次。异步发送，不会重试

consumer消费重试

(1) 重试队列： 如果Consumer端因为各种类型异常导致本次消费失败，为防止该消息丢失而需要将其重新回发给Broker端保存，保存这种因为异常无法正常消费而回发给MQ的消息队列称之为重试队列。 RocketMQ会为每个消费组都设置一个Topic名称为“%RETRY%+consumerGroup”的重试队列（这里需要注意的是，这个Topic的重试队列是针对消费组，而不是针对每个Topic设置的），用于暂时保存因为各种异常而导致Consumer端无法消费的消息。考虑到异常恢复起来需要一些时间，会为重试队列设置多个重试级别，每个重试级别都有与之对应的重新投递延时，重试次数越多投递延时就越大。RocketMQ对于重试消息的处理是先保存至Topic名称为“SCHEDULETOPICXXXX”的延迟队列中，后台定时任务按照对应的时间进行Delay后重新保存至“%RETRY%+consumerGroup”的重试队列中

(2) 死信队列： 由于有些原因导致Consumer端长时间的无法正常消费从Broker端Pull过来的业务消息，为了确保消息不会被无故的丢弃，那么超过配置的“最大重试消费次数”后就会移入到这个死信队列中。在RocketMQ中，SubscriptionGroupConfig配置常量默认地设置了两个参数，一个是retryQueueNums为1（重试队列数量为1个），另外一个是retryMaxTimes为16（最大重试消费的次数为16次）。Broker端通过校验判断，如果超过了最大重试消费次数则会将消息移至这里所说的死信队列。这里，RocketMQ会为每个消费组都设置一个Topic命名为“%DLQ%+consumerGroup"的死信队列。一般在实际应用中，移入至死信队列的消息，需要人工干预处理；

Consumer端回发消息至Broker端
(1) 业务方正常消费（CONSUMESUCCESS）： 正常情况下，设置ackIndex的值为consumeRequest.getMsgs().size() - 1，因此后面的遍历consumeRequest.getMsgs()消息集合条件不成立，不会调用回发消费失败消息至Broker端的方法—sendMessageBack(msg, context)。最后，更新消费的偏移量；

(2) 业务方消费失败（RECONSUMELATER）： 异常情况下，设置ackIndex的值为-1，这时就会进入到遍历consumeRequest.getMsgs()消息集合的for循环中，执行回发消息的方法—sendMessageBack(msg, context)。这里，首先会根据brokerName得到Broker端的地址信息，然后通过网络通信的Remoting模块发送RPC请求到指定的Broker上，如果上述过程失败，则创建一条新的消息重新发送给Broker，此时新消息的Topic为“%RETRY%+ConsumeGroupName”—重试队列的主题。其中，在MQClientAPIImpl实例的consumerSendMessageBack()方法中封装了ConsumerSendMsgBackRequestHeader的请求体，随后完成回发消费失败消息的RPC通信请求（业务请求码为：CONSUMERSENDMSGBACK）。倘若上面的回发消息流程失败，则会延迟5S后重新在Consumer端进行重新消费。与正常消费的情况一样，在最后更新消费的偏移量；

Broker端对于回发消息处理的主要流程
Broker端收到这条Consumer端回发过来的消息后，通过业务请求码（CONSUMERSENDMSGBACK）匹配业务处理器—SendMessageProcessor来处理。在完成一系列的前置校验（这里主要是“消费分组是否存在”、“检查Broker是否有写入权限”、“检查重试队列数是否大于0”等）后，尝试获取重试队列的TopicConfig对象（如果是第一次无法获取到，则调用createTopicInSendMessageBackMethod()方法进行创建）。根据回发过来的消息偏移量尝试从commitlog日志文件中查询消息内容，若不存在则返回异常错误。然后，设置重试队列的Topic—“%RETRY%+consumerGroup”至MessageExt的扩展属性“RETRYTOPIC”中，并对根据延迟级别delayLevel和最大重试消费次数maxReconsumeTimes进行判断，如果超过最大重试消费次数（默认16次），则会创建死信队列的TopicConfig对象（用于后面将回发过来的消息移入死信队列）。在构建完成需要落盘的MessageExtBrokerInner对象后，调用“commitLog.putMessage(msg)”方法做消息持久化。这里，需要注意的是，在putMessage(msg)的方法里会使用“SCHEDULETOPICXXXX”和对应的延迟级别队列Id分别替换MessageExtBrokerInner对象的Topic和QueueId属性值，并将原来设置的重试队列主题（“%RETRY%+consumerGroup”）的Topic和QueueId属性值做一个备份分别存入扩展属性properties的“REALTOPIC”和“REALQID”属性中。看到这里也就大致明白了，回发给Broker端的消费失败的消息并非直接保存至重试队列中，而是会先存至Topic为“SCHEDULETOPICXXXX”的定时延迟队列中。

在源码中搜索下关键字—“SCHEDULETOPICXXXX”，会发现Broker端还存在着一个后台服务线程—ScheduleMessageService（通过消息存储服务—DefaultMessageStore启动），通过查看源码可以知道其中有一个DeliverDelayedMessageTimerTask定时任务线程会根据Topic（“SCHEDULETOPICXXXX”）与QueueId，先查到逻辑消费队列ConsumeQueue，然后根据偏移量，找到ConsumeQueue中的内存映射对象，从commitlog日志中找到消息对象MessageExt，并做一个消息体的转换（messageTimeup()方法，由定时延迟队列消息转化为重试队列的消息），再次做持久化落盘，这时候才会真正的保存至重试队列中。看到这里就可以解释上面的疑问了，定时延迟队列只是为了用于暂存的，然后延迟一段时间再将消息移入至重试队列中。RocketMQ设定不同的延时级别delayLevel，并且与定时延迟队列相对应。

每个Consumer实例在启动的时候就默认订阅了该消费组的重试队列主题

发送顺序消息
发送消息是顺序的：需要同一线程发送一组消息，而调用的produce发送消息的方法也要是同步的。
broker存储消息是顺序的
consumer消费是顺序的：需要保证一个queue只在一个线程内被消费。
producer可以用MessageQueueSelector控制同一个订单号的mq投送到同一个messageQueue中

consumer使用MessageListenerOrderly控制消费的有序性，集群模式下，Consumer 更新属于自己的消息队列时，会向 Broker 锁定该消息队列（广播模式下不需要）。如果锁定失败，则更新失败，即该消息队列不属于自己，不能进行消费。

这是一个分布式锁，保证了一个queue只会被一个消费者锁定和消费。如果锁定成功，则添加到拉取任务中，如果锁定未成功，说明虽然发送了消息队列重新负载，但该消息队列还未被释放，本次负载周期不会进行消息拉取。Broker 消息队列锁会过期，默认配置 30s。因此，Consumer 需要不断向 Broker 刷新该锁过期时间，默认配置 20s 刷新一次。集群模式下，Consumer 移除自己的消息队列时，会向 Broker 解锁该消息队列（广播模式下不需要）。

先说一下ProcessQueue这个关键的数据结构。一个MessageQueue对应一个ProcessQueue，是一个有序队列，该队列记录一个queueId下所有从brokerpull回来的消息，如果消费成功了就会从队列中删除。ProcessQueue有序的原因是维护了一个TreeMap。

msgTreeMap：里面维护了从broker pull回来的所有消息，TreeMap是有序的，key是Long类型的，没有指定comparator，默认是将key强转为Comparable，然后进行比较，因为key是当前消息的offset，而Long实现了Comparable接口，所以msgTreeMap里面的消息是按照offset排序的。

所以是ProcessQueue保证了拉取回来的消息是有序的，继续上面说到的启动线程执行ConsumeRequest.run方法来消费消息。
