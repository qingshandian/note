数据库笔记

内连接查询，on条件是A表或者B表的唯一字段，则结果集是两表的交集，不是笛卡尔积。
假如，on条件是表中非唯一字段，则结果集是两表匹配到的结果集的笛卡尔积(局部笛卡尔积) 。


EXISTS 指定一个子查询，检测行的存在。语法：EXISTS subquery。参数 subquery 是一个受限的 SELECT 语句 （不允许有 COMPUTE 子句和 INTO 关键字）。结果类型为 Boolean，如果子查询包含行，则返回 TRUE。

NOT EXISTS 的作用与 EXISTS 正相反。如果子查询没有返回行，则满足 NOT EXISTS 中的 WHERE 子句。

按照连接池默认的配置MAX为6，一百台应用服务器连接一个MySQL ，所以会有600个连接落到数据库,按照一个请求的处理时间1ms的话， 那么一秒钟就能处理1000个请求， 600个连接的话可以处理60w的qps/tps请求了，这时候就已经远远超出单个DB的容量极限了。

数据库的连接都是附带状态的，事务的状态也是维持在连接上的，而一个连接在单位时间内只能处理一个事务请求， 所以需要多个连接来保证并发度，同时数据库（MySQL）也需要创建相应多的线程来绑定这个关系

InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现的特点意味着：只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁。

在实际应用中，要特别注意 InnoDB 行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。

1.在不通过索引条件查询的时候，InnoDB 确实使用的是表锁，而不是行锁。
2.由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，因此虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。应用设计的时候要注意这一点。
3.当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引还是普通索引，InnoDB 都会使用行锁来对数据加锁。
4.即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同的执行计划的代价来决定的。如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查 SQL 的执行计划，以确认是否真正使用了索引。

CHAR(M)定义的列的长度为固定的，M取值可以为0～255之间，当保存CHAR值时，在它们的右边填充空格以达到指定的长度。当检索到CHAR值时，尾部的空格被删除掉。在存储或检索过程中不进行大小写转换。CHAR存储定长数据很方便，CHAR字段上的索引效率级高，比如定义char(10)，那么不论你存储的数据是否达到了10个字节，都要占去10个字节的空间,不足的自动用空格填充。

VARCHAR(M)定义的列的长度为可变长字符串，M取值可以为0~65535之间，(VARCHAR的最大有效长度由最大行大小和使用的字符集确定。整体最大长度是65,532字节）。VARCHAR值保存时只保存需要的字符数，另加一个字节来记录长度(如果列声明的长度超过255，则使用两个字节)。VARCHAR值保存时不进行填充。当值保存和检索时尾部的空格仍保留，符合标准SQL。varchar存储变长数据，但存储效率没有CHAR高。如果一个字段可能的值是不固定长度的，我们只知道它不可能超过10个字符，把它定义为 VARCHAR(10)是最合算的。

CHAR和VARCHAR最大的不同就是一个是固定长度，一个是可变长度。


SHOW  TABLE  STATUS;

即使插入的记录被事务回滚，自增的id也会被占用掉，不会恢复

MySQL技术内幕:InnoDB存储引擎

磁盘结构和工作原理
外观类似留声机
机械硬盘 = 磁头组件 + 磁盘 + 控制电机

磁头组件 = 磁头 + 传动手臂 + 传动轴
磁头组件中最主要的部分是磁头，另外的两个部分可以看作是磁头的辅助装置。传动轴带动传动臂，使磁头到达指定的位置
磁头是硬盘中对盘片进行读写工作的工具，是硬盘中最精密的部位之一。磁头是用线圈缠绕在磁芯上制成的，工作原理则是利用特殊材料的电阻值会随着磁场变化的原理来读写盘片上的数据。硬盘在工作时，磁头通过感应旋转的盘片上磁场的变化来读取数据；通过改变盘片上的磁场来写入数据。为避免磁头和盘片的磨损，在工作状态时，磁头悬浮在高速转动的盘片上方，间隙只有0.1~0.3um，而不是盘片直接接触

磁头的移动是靠磁头驱动组件实现的，硬盘寻道时间的长短与磁头驱动组件关系非常密切

磁头的数量与盘片数量有关。一张单面的磁盘需要一个磁头，如果是双面的磁盘，则需要两个磁头，整个硬盘的磁头的数量就是各个盘片所需要的磁头的数量的总和。磁头可沿盘片的半径方向动作，（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的

磁盘 = 盘片 + 转轴

新买来的硬盘是不能直接使用的，必须对它进行分区进行格式化才能存储数据。经过格式化分区后，逻辑上每个盘片的每一面都会被分为磁道、扇区、柱面这几个虚拟的概念。

磁头靠近主轴接触的表面，即线速度最小的地方，是一个特殊的区域，它不存放任何数据，称为启停区或着陆区（LandingZone），启停区外就是数据区。

磁道
当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，这些圆形轨迹就叫磁道。磁道上的磁道是一组记录密度不同的同心圆。
这些磁道用肉眼是根本看不到的，因为他们仅是盘面上以特殊方式磁化了的一些磁化区，磁盘上的信息便是沿着这样的轨道存放的。相邻磁道之间并不是紧挨着的，这是因为磁化单元相隔太近时磁性会产生相互影响，同时也为磁头的读写带来困难，硬盘的每一个盘面有300～1 024个磁道，新式大容量硬盘每面的磁道数更多。在每个盘面的最外圈，离盘心最远的地方是“0”磁道，向盘心方向依次增长为1磁道，2磁道，等等。硬盘数据的存放就是从最外圈开始。

扇区
分区格式化磁盘时，每个盘片的每一面都会划分很多同心圆的磁道，而且还会将每个同心圆进一步的分割为多个相等的圆弧，这些圆弧就是扇区。为什么要进行扇区的划分呢？因为，读取和写入数据的时候，磁盘会以扇区为单位进行读取和写入数据，即使电脑只需要某个扇区内的几个字节的文件，也必须一次把这几个字节的数据所在的扇区中的全部512字节的数据全部读入内存，然后再进行筛选所需数据，所以为了提高电脑的运行速度，就需要对硬盘进行扇区划分。另外，每个扇区的前后两端都会有一些特定的数据，这些数据用来构成扇区之间的界限标志，磁头通过这些界限标志来识别众多的扇区。

柱面
硬盘通常由一个或多个盘片构成，而且每个面都被划分为数目相等的磁道，并从外缘开始编号（即最边缘的磁道为0磁道，往里依次累加）。如此磁盘中具有相同编号的磁道会形成一个圆柱，此圆柱称为磁盘的柱面。磁盘的柱面数与一个盘面上的磁道数是相等的。不同面上相同磁道编号则组成了一个圆柱面，即所称的柱面(Cylinder)。这里要注意，硬盘数据的读写是按柱面进行，即磁头读写数据时首先在同一柱面内从0磁头开始进行操作，依次向下在同一柱面的不同盘面(即磁头上)进行操作，只有在同一柱面所有的磁头全部读写完毕后磁头才转移到下一柱面，因为选取磁头只需通过电子切换即可，而选取柱面则必须通过机械切换。电子切换比从在机械上磁头向邻近磁道移动快得多。因此，数据的读写按柱面进行，而不按盘面进行。 读写数据都是按照这种方式进行，尽可能提高了硬盘读写效率。

由于硬盘是高精密设备，尘埃是其大敌，所以必须完全密封。

硬盘的工作原理

     现代硬盘寻道都是采用CHS(Cylinder Head Sector)的方式，硬盘读取数据时，读写磁头沿径向移动，移到要读取的扇区所在磁道的上方，这段时间称为寻道时间(seek time)。因读写磁头的起始位置与目标位置之间的距离不同，寻道时间也不同。目前硬盘一般为2到30毫秒，平均约为9毫秒。磁头到达指定磁道后，然后通过盘片的旋转，使得要读取的扇区转到读写磁头的下方，这段时间称为旋转延迟时间(rotational latencytime)。

访盘请求完成过程：

确定磁盘地址（柱面号，磁头号，扇区号），内存地址（源/目）：
       当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。

为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点：
1）首先必须找到柱面，即磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，
2）然后目标扇区旋转到磁头下，即磁盘旋转将目标扇区旋转到磁头下。这个过程耗费的时间叫做旋转时间。

即一次访盘请求（读/写）完成过程由三个动作组成：
1）寻道（时间）：磁头移动定位到指定磁道 
2）旋转延迟（时间）：等待指定扇区从磁头下旋转经过 
3）数据传输（时间）：数据在磁盘与内存之间的实际传输

因此在磁盘上读取扇区数据（一块数据）所需时间：

	Ti/o = tseek + tla + n*twm

其中:
tseek 为寻道时间
tla为旋转时间
twm 为传输时间

局部性原理与磁盘预读

由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：

当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中。由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。

预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。

磁盘碎片的产生

1.我们从原位置删除文件，重新建个文件重新写上”Hello, World!!”. –这就无意中延长了文件系统的读和写的时间。
2.打碎文件，就是在别的空的地方写上感叹号，也就是”身首异处”–这个点子不错，速度很快，而且方便，但是，这就同时意味着大大的减慢了读取下一个新文件的时间。
这里所说的方法二就像是我们的windows系统的存储方式，每个文件都是紧挨着的，但如果其中某个文件要更改的话，那么就意味着接下来的数据将会被放在磁盘其他的空余的地方。
如果这个文件被删除了，那么就会在系统中留下空格，久而久之，我们的文件系统就会变得支离破碎，碎片就是这么产生的。

我们的数据资料都是以信息的方式存储在盘面的扇区的磁道上,硬盘读取是由摇臂控制磁头从盘面的外侧向内侧进行读写的.所以外侧的数据读取速度会比内侧的数据快很多.其实我们的文件大多数的时候都是破碎的，在文件没有破碎的时候,摇臂只需要寻找1次磁道并由磁头进行读取,只需要1次就可以成功读取;但是如果文件破碎成 11处,那么摇臂要来回寻找11次磁道磁头进行11次读取才能完整的读取这个文件,读取时间相对没有破碎的时候就变得冗长.

由于硬盘生产商和操作系统换算不太一样，硬盘厂家以10进位的办法来换算，而操作系统是以2进位制来换算，所以在换算成M或者G 时，不同的算法结果却不一样；所以我们的硬盘有时标出的是80G，在操作系统下看却少几M




数据库：是物理操作系统文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合，在MYSQL数据库中，数据库文件可以是frm、MYD、MYI、ibd结尾的文件
数据库实例：是一个程序，是位于用户和操作系统之间的一层数据管理软件，用户对数据库数据的任何操作，包括数据库定义、数据查询、数据维护、数据库运行控制等都是在数据库实例下进行的，应用程序只有通过数据库实例才能和数据库打交道，它由后台线程以及一个共享内存区组成，数据库实例才是真正用于操作数据库文件的

数据库是由一个个文件（一般来说都是二进制文件）组成的，要对这些文件执行诸如SELECT、INSERT、UPDATE之类的数据库操作是不能通过简单的操作文件来更改数据库的内容，需要通过数据库实例来完成对数据库的操作

在MYSQL数据库中，实例与数据库的关系通常是一一对应的，即一个实例对应一个数据库，在集群情况下可能存在一个数据库被多个数据实例使用的情况

MYSQL被设计为一个单进程多线程架构的数据库，与SQL Server类似，但与Oracle多进程的架构不同


							  MYSQL体系结构

							连接方（JDBC、ODBC）

						连接池（鉴权、连接限制、内存检查）

	  SQL接口（DML、DDL、存储过程、触发器）   解析器      分析器        缓存	

	        插件式存储引擎（内存、索引、存储管理）（MyISAM、InnoDB）	

	          文件系统                      文件和日志（redo、undo）


InnoDB存储引擎
支持事务，其设计目标主要面向在线事务处理的应用。其特点是行锁设计、支持外键，并支持类似于Oracle的非锁定读，即默认读取操作不会产生锁。从MYSQL5.5.8开始，就是默认的存储引擎
InnoDB通过使用多版本并发控制（MVCC）来获得高并发性，并且实现了SQL标准的4种隔离级别，同时，使用一个被称为next-key locking的策略来避免幻读现象的产生
对于表中数据的存储，InnoDB存储引擎采用了聚集的方式，因此每张表的存储都是按主键的顺序进行存放，如果没有显式地在表定义时指定主键，InnoDB存储引擎会为每一行生成一个6字节的ROWID，并以此作为主键

MYISAM存储引擎
不支持事务、表锁设计，支持全文索引，主要面向一些OLAP数据库应用，此外，它的缓冲池只缓存索引文件，而不缓冲数据文件，这点和大多数的数据库都不同

NDB存储引擎
join操作是在MYSQL数据库层完成的，而不是在存储引擎层完成的，这意味着，复杂的连接操作需要巨大的网络开销，因此查询速度很慢

Memory存储引擎
将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据都将消失，默认使用哈希索引，而不是B+树索引，存储变长字段varchar时是按照定长字段（char）的方式进行的

连接MYSQL操作是一个连接进程和mysql数据库实例（也是一个进程）进行通信，本质上是进程间的通信，常用的进程通信方式有管道、TCP/IP、UNIX域套接字，mysql数据库提供的连接方式从本质上看都是上述提及的进程通信方式

TCP/IP是网络中使用的最多的一种数据库连接方式，这种方式在TCP/IP连接上建立一个基于网络的连接请求，一般情况下客户端在一台服务器，而mysql实例在另一台服务器上，这两台机器通过一个TCP/IP网络连接


InnoDB存储引擎
是事务安全的MYSQL存储引擎，设计上采用了类似于Oracle数据库的架构，通常来说，InnoDB存储引擎是OLTP应用中核心表的首选存储引擎
是第一个完整支持ACID事务的MYSQL存储引擎

InnoDB存储引擎有多个内存块，可以认为这些内存块组成了一个大的内存池，负责如下工作：
维护所有线程需要访问的多个内部数据结构
缓存磁盘上的数据，方便快速地读取，同时在对磁盘文件的数据修改之前在这里缓存
redo log 缓存

后台线程 后台线程 后台线程 后台线程 后台线程

		InnoDB存储引擎内存池

		     数据库文件

后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存是最新的数据，此外将已修改的数据文件刷新到磁盘文件
多个不同的后台线程，负责处理不同的任务

Master Thread
是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新，合并插入缓冲，UNDO页的回收

IO Thread
在InnoDB存储引擎中大量使用了AIO来处理写IO请求，这样可以极大提高数据库的性能。而IO Thread的工作主要是负责这些IO请求的回调处理

Purge Thread
事务被提交后，其所使用的undolog可能不再需要，因此需要PurgeThread来回收已经使用并分配的undo页


内存
缓冲池
InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此可将其视为基于磁盘的数据库系统，由于CPU速度与磁盘速度之间的鸿沟，基于磁盘的数据库系统通常使用缓冲池技术来提高数据库的整体性能
缓冲池简单来说就是一块内存区域，在数据库中进行读取页的操作，首先将从磁盘读到的页存放在缓冲池中，这个过程称为将页FIX在缓冲池中。下一次再读取相同的页时，首先判断该页是否在缓冲池中，若在，称该页在缓冲池中被命中，直接读取该页
对于数据库中页的修改操作，则首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上，但刷新的操作并不是在每次页更新时触发，而是通过一种称为CheckPoint的机制回刷磁盘
缓冲池的大小直接影响着数据库的整体性能

缓冲池：数据页、索引页、插入缓冲、锁信息、自适应哈希索引、数据字典信息
重做日志缓冲

允许有多个缓冲池实例，每个页根据哈希值平均分配到不同缓冲实例中
数据库中的缓冲池是通过LRU（Latest Recent Used最近最少使用）算法来进行管理的，最频繁使用的页在LRU列表的前端，反之在后端，当缓冲池不能存放读取到的页时，将首先释放后端的页
InnoDB缓冲池中页的大小默认为16KB

在LRU列表中的页被修改后，称该页为脏页，即缓冲池中的页和磁盘上的页数据产生了不一致，这时数据库会通过CheckPoint机制将脏页刷新回磁盘，Flush列表中的页即为脏页列表。需要注意的是，脏页即存在于LRU列表中，也存在于Flush列表中，LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘。两者互不影响

重做日志缓冲
InnoDB存储引擎首先将重做日志信息先放入到这个缓冲区，然后按一定频率将其刷新到重做日志文件，重做日志缓冲一般不需要设置得很大，因为一般情况下每一秒会将重做日志缓冲刷新到日志文件，因此用户只需要保证每秒产生的事务量在这个缓冲大小之内即可

在通常情况下，8MB的重做日志缓冲池足以满足绝大部分的应用，重做日志在下列三种情况下会将重做日志缓冲回刷到磁盘的重做日志文件中
1.Master Thread每一秒将重做日志缓冲刷新到重做日志文件
2.每个事务提交时
3.当重做日志缓冲池剩余空间小于1/2时

CheckPoint技术

缓冲池的设计目的为了协调CPU速度与磁盘速度的鸿沟，因此页的操作首先都是在缓冲池中完成的，如果一条DML语句，如update或delete改变了页中的记录，那么此时页是脏的，即缓冲池中的页的版本要比磁盘的新，数据库需要将新版本的页从缓冲池刷新到磁盘
倘若每次一个页发生变化，就将新页的版本刷新到磁盘，那么这个开销是非常大的。若热点数据集中在某几个页中，那么数据库的性能将变得非常差，同时，如果在缓冲池将页的新版本刷新到磁盘时发生了宕机，那么数据就不能恢复了。为了避免发生数据丢失问题，当前事务数据库系统普遍都采用了Write Ahead Log策略，即当事务提交时，先写重做日志，再修改页。当由于发生宕机而导致数据丢失时，通过重做日志来完成数据的恢复，这也是事务ACID中D的要求

思考下面的场景，如果重做日志可以无限地增大，同时缓冲池也足够大，能够缓冲所有数据库的数据，那么是不需要将缓冲池中页的新版本刷新回磁盘。因为当发生宕机时，完全可以通过重做日志来恢复整个数据库系统中的数据到宕机发生时刻，但是这需要两个前提条件：
1缓冲池可以缓存数据库中的所有数据
2重做日志可以无限增大
对于第一点，当前3TB的MYSQL数据库以并不少见，但是3TB的内存却非常少见
对于第二点，重做日志可以无限增大，但是重做日志越大，宕机后数据库的恢复时间就越长，恢复的代价会越来越大
因此CheckPoint检查点技术的目的是解决以下几个问题：
缩短数据库的恢复时间
缓冲池不够用时，将脏页刷新到磁盘
重做日志不可用时，刷新脏页
当数据库发生宕机时，数据库不需要重做所有日志，因为CheckPoint之前的页都已经刷新回磁盘，只需对检查点之后的重做日志进行恢复
当缓冲池不够用时，根据LRU算法会移除最近最少使用的页，若此页为脏页，那么需要强制执行CheckPoint，将脏页数据回刷
重做日志出现不可用的情况是因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是让其无限增大的，

在InnoDB存储引擎中，检查点发生的时间、条件及脏页的选择都非常复杂，其所做的事情无外乎是将缓冲池的数据回刷
检查点分为以下两种
Sharp CheckPoint
Fuzzy CheckPoint
Sharp检查点发生在数据库关闭时将所有的脏页都刷回磁盘
数据库在运行时使用Fuzzy检查点，即只刷新一部分脏页
对于Master Thread中发生的检查点，差不多以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘，这个过程是异步的，用户查询线程不会阻塞
检查点既会发生在LRU列表也会发生在脏页列表

Master Thread工作方式
InnoDB存储引擎的主要工作都是在一个单独的后台线程Master Thread中完成的
Master Thread具有最高级别优先级，其内部由多个循环组成：主循环、后台循环、刷新循环、暂停循环，根据数据库运行状态进行切换
主循环每秒或者每10秒进行一次操作
每秒一次的操作包括：
1.日志缓冲刷新到磁盘，即使这个事务还没有提交
2.合并插入缓冲
3.至多刷新100个InnoDB脏页到磁盘
即时某个事物还没有提交，InnoDB存储引擎仍然每秒会将重做日志缓冲中的内容刷新到重做日志文件
若当前没有用户活动，就会切换到后台循环，后台循环执行以下操作：
1.删除无用的Undo页
2.合并20个插入缓冲
3.跳回主循环

InnoDB关键特性

插入缓冲
两次写
自适应哈希索引
异步IO
刷新邻接页

插入缓冲

insert buffer可能是InnoDB存储引擎关键特性中最令人激动和兴奋的一个功能
插入缓冲和数据页一样，也是物理页的一个组成部分
在InnoDB存储引擎中，主键是行唯一的标识符，通常应用程序中行记录的插入顺序是按照主键递增的顺序进行插入的，因此，插入聚集索引一般是顺序的，不需要磁盘的随机读取
注意：并不是所有的主键插入都是顺序的，若主键类是UUID或者自增主键插入了指定的值，那么可能会导致插入不连续的情况

但是不可恩每张表上只有一个聚集索引，更多情况下，一张表上有多个非聚集的辅助索引，如下：
CREATE TABLE t {
	a INT AUTO_INCREMENT,
	b VARCHAR(30),
	PRIMARY KEY(a),
	key(b)
};
在进行插入操作时，数据页的存放还是按主键a顺序存放的，但是对于非聚集索引叶子节点的插入不再是顺序的了，这时就需要离散地访问非聚集索引页，由于随机读取的存在而导致了插入操作性能下降，当然这并不是这个b字段上索引的错误，而是因为B+树的特性决定了非聚集索引插入的离散性
对此，InnoDB存储引擎开创性地设计了Insert Buffer，对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入，若不在，则先放入到一个Insert Buffer对象中，好似欺骗数据库这个非聚集索引已经插入到叶子节点，而实际并没有，只是存放在另一个位置，然后再以一定的频率和情况进行Insert Buffer和辅助索引页子节点的merge操作，这时通常能够将多个插入合并到一个操作中（因为在一个索引页中），这就大大提高了对于非聚集索引插入的性能

Insert Buffer的使用需要同时满足以下两个条件：
索引是辅助索引
索引不是唯一的
若应用程序进行大量的插入操作，这些都涉及了不唯一的非聚集索引，也就是使用了Insert Buffer，若此时MYSQL数据库发生了宕机，会有大量的插入缓冲并没有合并到实际的非聚集索引中去，因此这时恢复可能需要很长的时间
辅助索引不能是唯一的，因为在插入缓冲时，数据库并不去查找索引页来判断插入记录的唯一性，这个判断比较耗费性能

目前插入缓冲存在的一个问题是，在写密集的情况下，插入缓冲会占用过多的缓冲池内存，默认最大可以占用到1/2的缓冲池内存

change buffer
insert buffer的升级，InnoDB存储引擎可以对DML操作——Insert、Delete、Update都进行缓冲，分别是Insert Buffer、Delete Buffer、Purge Buffer
change buffer适用的对象依然是非唯一的辅助索引

Insert Buffer的内部实现
Insert Buffer的数据结构是一颗B+树，在MYSQL4.1之间的版本中每张表有一棵Insert Buffer B+树，现在的版本中，全局只有一棵，负责对所有的表辅助索引进行Insert Buffer
Insert Buffer是一棵B+树，因此其也由叶子节点和非叶节点组成，非叶节点存放的是查询的search key，其构造如下：
space + marker + offset
space表示待插入记录所在表的表空间id，在InnoDB存储引擎中，每张表有一个唯一的space id，marker用来兼容老版本，offset表示页所在的偏移量

当一个辅助索引要插入到页时，如果这个页不在缓冲池中，那么该索引会先插入到insert buffer中，插入之前，InnoDB存储引擎首先根据上述规则构造一个search key，接下来查询Insert Buffer这棵树，然后再将这条记录插入叶子节点中

因为启用Insert Buffer索引后，辅助索引页中的记录可能被插入到Insert Buffer B+树中，所以为了保证每次Merge Insert Buffer页必须成功，还需要有一个特殊的页用来标记每个辅助索引页的可用空间，这个页的类型为Insert Buffer Bitmap

Merge Insert Buffer
辅助索引从Insert Buffer合并到真正的索引中可能发生在以下几种情况下：
1.辅助索引页被读取到缓冲池时
2.Insert Buffer Bitmap页追踪到该辅助索引页已无可用空间时
3.Master Thread
第一种情况例如在执行Select时，需要检查该辅助索引页是否有记录存放于Insert Buffer B+树中，若有，则将Insert Buffer B+树中该页的记录插入到该辅助索引页中，而且如果该页有多次插入则会被合并为一次操作
Insert Buffer Bitmap页用来追踪每个辅助索引页的可用空间，并至少有1/32页的空间，若检测后发现空间不足1/32，则会进行一次强制合并操作
Master Thread线程每秒或每10秒会进行一次Merge Insert Buffer操作，并且执行merge操作的不止一个页


两次写
double write带给InnoDB存储引擎的是数据页的可靠性

当数据库发生宕机时，可能InnoDB存储引擎正在写入某个页到表中，而这个页只写了一部分，比如16KB的页，只写了前4KB，之后发生了宕机，这种情况被称为部分写失效，这是该页的数据是被损坏的（可能一条记录部分字段是对的，部分字段是错的）
如果写失效，可以通过重做日志进行恢复，但是重做日志记录的是对页的物理操作，如果这个页本身已经发生了损坏，再对其进行重做是没有意义的。这就是说，在应用重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是doublewrite
doublewrite由两部分组成，一部分是内存中的doublewrite buffer，大小为2MB，另一部分是物理磁盘上共享表空间中连续128个页，大小同样为2MB
在对缓冲池的脏页进行刷新时，并不直接写磁盘，而是将脏页先复制到内存中的doublewrite buffer，之后分两次写入物理磁盘
参数skip_innodb_doublewrite可以禁止使用doubleWrite功能，不过，对于需要提供数据高可靠性的服务器，任何时候用户都应该开启doubleWrite功能


自适应哈希索引
哈希的查找时间复杂度为O(1)，B+树的复杂度取决于树的高度，在生产环境中，高度一般为3~4层
InnoDB存储引擎会监控对表上各索引页的查询，如果观察到建立哈希索引可以带来速度提升，则建立哈希索引，称之为自适应哈希索引AHI

AHI是通过缓冲池的B+树页构造而来，因此建立的速度很快，而且不需要对整张表构建哈希索引，InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引

哈希索引只能用来搜索等值的查询，对于其他查找类型，如范围查找，是不能使用哈希索引的

