数据库笔记

内连接查询，on条件是A表或者B表的唯一字段，则结果集是两表的交集，不是笛卡尔积。
假如，on条件是表中非唯一字段，则结果集是两表匹配到的结果集的笛卡尔积(局部笛卡尔积) 。


EXISTS 指定一个子查询，检测行的存在。语法：EXISTS subquery。参数 subquery 是一个受限的 SELECT 语句 （不允许有 COMPUTE 子句和 INTO 关键字）。结果类型为 Boolean，如果子查询包含行，则返回 TRUE。

NOT EXISTS 的作用与 EXISTS 正相反。如果子查询没有返回行，则满足 NOT EXISTS 中的 WHERE 子句。

按照连接池默认的配置MAX为6，一百台应用服务器连接一个MySQL ，所以会有600个连接落到数据库,按照一个请求的处理时间1ms的话， 那么一秒钟就能处理1000个请求， 600个连接的话可以处理60w的qps/tps请求了，这时候就已经远远超出单个DB的容量极限了。

数据库的连接都是附带状态的，事务的状态也是维持在连接上的，而一个连接在单位时间内只能处理一个事务请求， 所以需要多个连接来保证并发度，同时数据库（MySQL）也需要创建相应多的线程来绑定这个关系

InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现的特点意味着：只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁。

在实际应用中，要特别注意 InnoDB 行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。

1.在不通过索引条件查询的时候，InnoDB 确实使用的是表锁，而不是行锁。
2.由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，因此虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。应用设计的时候要注意这一点。
3.当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引还是普通索引，InnoDB 都会使用行锁来对数据加锁。
4.即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同的执行计划的代价来决定的。如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查 SQL 的执行计划，以确认是否真正使用了索引。

CHAR(M)定义的列的长度为固定的，M取值可以为0～255之间，当保存CHAR值时，在它们的右边填充空格以达到指定的长度。当检索到CHAR值时，尾部的空格被删除掉。在存储或检索过程中不进行大小写转换。CHAR存储定长数据很方便，CHAR字段上的索引效率级高，比如定义char(10)，那么不论你存储的数据是否达到了10个字节，都要占去10个字节的空间,不足的自动用空格填充。

VARCHAR(M)定义的列的长度为可变长字符串，M取值可以为0~65535之间，(VARCHAR的最大有效长度由最大行大小和使用的字符集确定。整体最大长度是65,532字节）。VARCHAR值保存时只保存需要的字符数，另加一个字节来记录长度(如果列声明的长度超过255，则使用两个字节)。VARCHAR值保存时不进行填充。当值保存和检索时尾部的空格仍保留，符合标准SQL。varchar存储变长数据，但存储效率没有CHAR高。如果一个字段可能的值是不固定长度的，我们只知道它不可能超过10个字符，把它定义为 VARCHAR(10)是最合算的。

CHAR和VARCHAR最大的不同就是一个是固定长度，一个是可变长度。


SHOW  TABLE  STATUS;

即使插入的记录被事务回滚，自增的id也会被占用掉，不会恢复



磁盘结构和工作原理
外观类似留声机
机械硬盘 = 磁头组件 + 磁盘 + 控制电机

磁头组件 = 磁头 + 传动手臂 + 传动轴
磁头组件中最主要的部分是磁头，另外的两个部分可以看作是磁头的辅助装置。传动轴带动传动臂，使磁头到达指定的位置
磁头是硬盘中对盘片进行读写工作的工具，是硬盘中最精密的部位之一。磁头是用线圈缠绕在磁芯上制成的，工作原理则是利用特殊材料的电阻值会随着磁场变化的原理来读写盘片上的数据。硬盘在工作时，磁头通过感应旋转的盘片上磁场的变化来读取数据；通过改变盘片上的磁场来写入数据。为避免磁头和盘片的磨损，在工作状态时，磁头悬浮在高速转动的盘片上方，间隙只有0.1~0.3um，而不是盘片直接接触

磁头的移动是靠磁头驱动组件实现的，硬盘寻道时间的长短与磁头驱动组件关系非常密切

磁头的数量与盘片数量有关。一张单面的磁盘需要一个磁头，如果是双面的磁盘，则需要两个磁头，整个硬盘的磁头的数量就是各个盘片所需要的磁头的数量的总和。磁头可沿盘片的半径方向动作，（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的

磁盘 = 盘片 + 转轴

新买来的硬盘是不能直接使用的，必须对它进行分区进行格式化才能存储数据。经过格式化分区后，逻辑上每个盘片的每一面都会被分为磁道、扇区、柱面这几个虚拟的概念。

磁头靠近主轴接触的表面，即线速度最小的地方，是一个特殊的区域，它不存放任何数据，称为启停区或着陆区（LandingZone），启停区外就是数据区。

磁道
当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，这些圆形轨迹就叫磁道。磁道上的磁道是一组记录密度不同的同心圆。
这些磁道用肉眼是根本看不到的，因为他们仅是盘面上以特殊方式磁化了的一些磁化区，磁盘上的信息便是沿着这样的轨道存放的。相邻磁道之间并不是紧挨着的，这是因为磁化单元相隔太近时磁性会产生相互影响，同时也为磁头的读写带来困难，硬盘的每一个盘面有300～1 024个磁道，新式大容量硬盘每面的磁道数更多。在每个盘面的最外圈，离盘心最远的地方是“0”磁道，向盘心方向依次增长为1磁道，2磁道，等等。硬盘数据的存放就是从最外圈开始。

扇区
分区格式化磁盘时，每个盘片的每一面都会划分很多同心圆的磁道，而且还会将每个同心圆进一步的分割为多个相等的圆弧，这些圆弧就是扇区。为什么要进行扇区的划分呢？因为，读取和写入数据的时候，磁盘会以扇区为单位进行读取和写入数据，即使电脑只需要某个扇区内的几个字节的文件，也必须一次把这几个字节的数据所在的扇区中的全部512字节的数据全部读入内存，然后再进行筛选所需数据，所以为了提高电脑的运行速度，就需要对硬盘进行扇区划分。另外，每个扇区的前后两端都会有一些特定的数据，这些数据用来构成扇区之间的界限标志，磁头通过这些界限标志来识别众多的扇区。

柱面
硬盘通常由一个或多个盘片构成，而且每个面都被划分为数目相等的磁道，并从外缘开始编号（即最边缘的磁道为0磁道，往里依次累加）。如此磁盘中具有相同编号的磁道会形成一个圆柱，此圆柱称为磁盘的柱面。磁盘的柱面数与一个盘面上的磁道数是相等的。不同面上相同磁道编号则组成了一个圆柱面，即所称的柱面(Cylinder)。这里要注意，硬盘数据的读写是按柱面进行，即磁头读写数据时首先在同一柱面内从0磁头开始进行操作，依次向下在同一柱面的不同盘面(即磁头上)进行操作，只有在同一柱面所有的磁头全部读写完毕后磁头才转移到下一柱面，因为选取磁头只需通过电子切换即可，而选取柱面则必须通过机械切换。电子切换比从在机械上磁头向邻近磁道移动快得多。因此，数据的读写按柱面进行，而不按盘面进行。 读写数据都是按照这种方式进行，尽可能提高了硬盘读写效率。

由于硬盘是高精密设备，尘埃是其大敌，所以必须完全密封。

硬盘的工作原理

     现代硬盘寻道都是采用CHS(Cylinder Head Sector)的方式，硬盘读取数据时，读写磁头沿径向移动，移到要读取的扇区所在磁道的上方，这段时间称为寻道时间(seek time)。因读写磁头的起始位置与目标位置之间的距离不同，寻道时间也不同。目前硬盘一般为2到30毫秒，平均约为9毫秒。磁头到达指定磁道后，然后通过盘片的旋转，使得要读取的扇区转到读写磁头的下方，这段时间称为旋转延迟时间(rotational latencytime)。

访盘请求完成过程：

确定磁盘地址（柱面号，磁头号，扇区号），内存地址（源/目）：
       当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。

为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点：
1）首先必须找到柱面，即磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，
2）然后目标扇区旋转到磁头下，即磁盘旋转将目标扇区旋转到磁头下。这个过程耗费的时间叫做旋转时间。

即一次访盘请求（读/写）完成过程由三个动作组成：
1）寻道（时间）：磁头移动定位到指定磁道 
2）旋转延迟（时间）：等待指定扇区从磁头下旋转经过 
3）数据传输（时间）：数据在磁盘与内存之间的实际传输

因此在磁盘上读取扇区数据（一块数据）所需时间：

	Ti/o = tseek + tla + n*twm

其中:
tseek 为寻道时间
tla为旋转时间
twm 为传输时间

局部性原理与磁盘预读

由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：

当一个数据被用到时，其附近的数据也通常会马上被使用。
程序运行期间所需要的数据通常比较集中。
由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。

预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。


磁盘碎片的产生

1.我们从原位置删除文件，重新建个文件重新写上”Hello, World!!”. –这就无意中延长了文件系统的读和写的时间。
2.打碎文件，就是在别的空的地方写上感叹号，也就是”身首异处”–这个点子不错，速度很快，而且方便，但是，这就同时意味着大大的减慢了读取下一个新文件的时间。
这里所说的方法二就像是我们的windows系统的存储方式，每个文件都是紧挨着的，但如果其中某个文件要更改的话，那么就意味着接下来的数据将会被放在磁盘其他的空余的地方。
如果这个文件被删除了，那么就会在系统中留下空格，久而久之，我们的文件系统就会变得支离破碎，碎片就是这么产生的。

我们的数据资料都是以信息的方式存储在盘面的扇区的磁道上,硬盘读取是由摇臂控制磁头从盘面的外侧向内侧进行读写的.所以外侧的数据读取速度会比内侧的数据快很多.其实我们的文件大多数的时候都是破碎的，在文件没有破碎的时候,摇臂只需要寻找1次磁道并由磁头进行读取,只需要1次就可以成功读取;但是如果文件破碎成 11处,那么摇臂要来回寻找11次磁道磁头进行11次读取才能完整的读取这个文件,读取时间相对没有破碎的时候就变得冗长.

由于硬盘生产商和操作系统换算不太一样，硬盘厂家以10进位的办法来换算，而操作系统是以2进位制来换算，所以在换算成M或者G 时，不同的算法结果却不一样；所以我们的硬盘有时标出的是80G，在操作系统下看却少几M

Mysql索引的高效性的原理得益于Mysql索引的实现，B+树，而B+树是B树的一种变种的数据结构，这两种数据结构都是为了磁盘和直接存储设备而设计的。是因为他们能够有效的减少磁盘IO过于频繁带来的磁盘读写效率低下问题

IO是大部分系统性能的瓶颈，网络IO的阻塞和磁盘IO的耗时

							
							寄存器
				内存存储器  高速缓存（CACHE）
							主存
计算机存储系统

				外部存储器  硬盘，光盘

主存存取原理：

从抽象的角度看，主存是由一系列的存储单元组成的矩阵，每个存储单元可以存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。如图展示了一个4 x 4的主存模型。

主存存取过程：

当系统从主存读取数据时，则将地址信号放到地址总线上，主存读到地址信号时，解析信号并定位到指定的存储单元，然后将存储单元的数据放到数据总线上，供其他部件读取。
当系统向主存写数据时，则将地址信号和数据分别放到地址总线和数据总线上，主存读取两个总线的内容，做响应的写操作。






B+Tree索引的性能分析
为什么要用B+树做索引？
哈希结构：如果要进行范围查询（大于4的数据），那这个索引就完全没用了。
二叉树查找树：数据量多的时候，树会很高，需要多次I/O操作。
B+树：所有记录节点存放在叶子节点上，且是顺序存放，由各叶子节点指针进行连接。如果从最左边的叶子节点开始顺序遍历，能得到所有键值的顺序排序。
1.B+树的高度一般为2-4层，所以查找记录时最多只需要2-4次IO，相对二叉平衡树已经大大降低了。
2.范围查找时，能通过叶子节点的指针获取数据。例如查找大于等于3的数据，当在叶子节点中查到3时，通过3的尾指针便能获取所有数据，而不需要再像二叉树一样再获取到3的父节点。

机械硬盘的连续读写性能很好，但随机读写性能很差。

顺序访问：内存访问速度是硬盘访问速度的6~7倍（kafka的特点，以后有机会的话再讲一讲）
随机访问：内存访问速度就要比硬盘访问速度快上10万倍以上

随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上。
而在实际的磁盘存储里，由于磁盘碎片的原因，文件是很少顺序存储的，因为这样的维护成本会很高。

聚集索引

							磁盘块0
							| P1 | 3 | P2 | 9 | P3 |


		      磁盘块1	  <----->	  磁盘块2	  <----->	   磁盘块3
		|  0  |  1  |  2  |		|  3  |  4  |  6  |		|  9  |  10   |     |
		| Fla | Sli | Bob |		| Ang | Tom | Rok |		| Jak |  Cra  |     |

P1指向磁盘块1 P2指向磁盘块2 P3指向磁盘块3，

叶子节点存放了整张表的所有行数据。
非叶子节点并不存储行数据，是为了能存储更多索引键，从而降低B+树的高度，进而减少IO次数。
聚集索引的存储在物理上并不是连续的，每个数据页在不同的磁盘块，通过一个双向链表来进行连接。（重要）

查找：假设要查找数据项6
把根节点由磁盘块0加载到内存，发生一次IO，在内存中用二分查找确定6在3和9之间；
通过指针P2的磁盘地址，将磁盘2加载到内存，发生第二次IO，再在内存中进行二分查找找到6，结束。

这里只进行了两次IO，实际上，每个磁盘块大小为4K，3层的B+树可以表示上百万的数据，也就是每次查找只需要3次IO，所以索引对性能的提高将是巨大的。
所以说B+树索引并不能直接找到具体的行，只是找到被查找行所在的页，然后DB通过把整页读入内存，再在内存中查找。

一般情况，用PRIMARY KEY来作为聚集索引。
如果没有定义PRIMARY KEY，将会用第一个UNIQUE且NOT NULL的列来作为聚集索引。
如果表没有合适的UNIQUE索引，会内部根据行ID值生成一个隐藏的聚簇索引GEN_CLUST_INDEX。

B+树非聚集索引
每个表可以有多个辅助索引
通过辅助索引查数据时，先查找辅助索引获得聚集索引的主键，然后通过主键索引来查找完整的行记录。
通过非主键索引比主键索引查找速度要慢一倍。

							磁盘块0
							| P1 | Fla | P2 | Sli | P3 |


		      磁盘块1	  <----->	  磁盘块2	  <----->	   磁盘块3
		|  Ang  |  Bob  |  Cra  |		|  Fla  |  Jak  |  Rok  |		|  Sli  |  Tom   |     |
主键：	|   3   |   2   |   10  |		|   0   |   9   |   6   |		|   1   |   4    |     |

查找：获取NAME=Jake的数据
第一阶段：通过辅助索引查到主键索引的主键

把idx_name索引的根节点由磁盘块0加载到内存，发生一次IO，查找到在P2指针中
根据P2指针的磁盘地址，加载磁盘块2到内存，发生第二次IO，查找到Jake节点以及它的主键索引9

第二阶段：通过主键索引找到完整的行记录

把根节点由磁盘块0加载到内存，发生一次IO，在内存中用二分查找确定9在P3指针中
通过指针P3的磁盘地址，将磁盘3加载到内存，发生第二次IO，再在内存中进行二分查找找到9，以及它的行记录，



我们首先提一个问题， B+树比平衡二叉树在索引数据方面要快么？

大多数人可能认为肯定还是B+树快，毕竟存储同样多的数据，100阶的B+树肯定比平衡二叉树的高度要低的多。但是别忘了B树在一个结点可能需要比较很多次才能找到下一层的结点，但是平衡二叉树只要比较一次就可以向下走一层。所以综合起来，其实两者索引的速度几乎（甚至说就是）是一样的。最简单的道理，一颗4阶B树就是一颗红黑树，比较的次数完全一样。那么我们为什么还要使用B+树呢？这是因为上面说索引速度相当的前提是两者的数据结构都位于内存中，当我们要在磁盘上索引一个记录时，将磁盘中的数据传输到内存中才是花费时间的大头，而在内存中的索引过程所花的时间基本是可以忽略不计的。在磁盘中以B+树的形式组织数据就有着天然的优势。要解释这个道理，我们必须先强调一个概念，主存和磁盘之间的数据交换不是以字节为单位的，而是以n个扇区为单位的（一个扇区有512字节），通常是4KB（8个扇区），8KB（16个扇区），16KB，……64KB为单位的。
假设，我们现在选择4KB作为内存和磁盘之间的传输单位，那么我们在设计B+树的时候，不论是索引结点还是叶子结点都使用4KB作为结点的大小。我们这时不妨再假设一个记录的大小是1KB，那么一个叶子结点可以存4个记录。而对于索引结点（大小也是4KB），由于只需要存key值和相应的指针，所以一个索引结点可能可以存储100~150个分支，我们不妨就取100吧。当然这和B树和B+树的插入、删除图文详解第2节和第3节中的情况不太一样，因为现在索引结点的阶数是100，而叶子结点的阶数是4，两者并不一致，但这并没有什么问题。
我们考虑如上图所示的B+树，下面的B+树有三层，两层是索引结点，最后一层是叶子结点。那么这个三层的B+树最多可以存400万个记录。如果这个B+树存储到硬盘中，我们怎么根据记录的key找到对应的记录呢？首先我们要读取这个B+树的根结点到内存（花费一个IO的时间）然后在内存中进行索引，根据key找到对应的分支，再将这个分支所指向的第二层索引结点读取到内存中（花费第二个IO时间）然后在内存中进行索引，同样根据key找到对应的分支，而这个分支指向的就是叶子结点，我们最后将这个叶子结点读取到内存中（花费的第三个IO时间）判断是否存在这个记录。这样我们只需要通过三次IO时间就从400万个记录中找到了对应的key记录，可以说是非常快了。快速的原因是，索引结点中不存数据，只存键和指针，所以一个索引结点就可以存储大量的分支，而一个索引结点只需要一次IO即可读取到内存中。

我们现在再考虑一个问题，当记录的大小可变时，叶子结点中记录该如何存储？

这个时候有两种极限情况。

1）假设叶子结点的阶数仍然为4，但每个记录仅仅有100个字节，显然当叶子结点中存满4个记录后，叶子结点中仍然有大量的剩余空间。这个时候我们能不能直接向该叶子结点中插入数据，而不必分裂这个叶子结点（分裂指在磁盘中的分裂）？答案是可以，有人一定会说，这不就违反B+树的定义了么？的确违反了，但是B+树之所以定义阶数的目的是为了平衡（或者说增强）每一个分支的索引效率，不过这个优点仅当整个B+树都位于内存时才能体现出来。当B+树存储在磁盘中的情况时，IO效率才是第一要考虑的因素。CPU在某个结点内部多比较几次或少比较几次和IO花费的时间相比就不值得一提了。而不分裂反而能提升B+树的IO效率，因为分裂需要更多的IO次数。综合起来了说就是，文件系统及数据库中的B+树是不考虑阶数这一个概念的，结点（即包括叶子结点，也包括索引结点）中仅遵行一个规则，如果剩余空间够大那么就存入数据，如果剩余空间不够，只能分裂后再存入。

2）如果某条记录太大，即使叶子结点中还剩余一多半的空间但仍然存不下怎么办？这个时候MySql称之为行溢出，简单的解决方式就是把记录存储在溢出页（磁盘的其它空闲地方）中，然后叶子结点中存储的是这个记录的指针。

在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k，而对于我们的InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K。


oracle一般使用堆表，mysql的innodb是索引组织表

堆表以一种显然随机的方式管理，数据插入时时存储位置是随机的，主要是数据库内部块的空闲情况决定，数据会放在最合适的地方，而不是以某种特定顺序来放置。堆组织表的存储速度因为不用考虑排序, 所以存储速度会比较快. 但是要查找符合某个条件的记录, 就必须得读取全部的记录以便筛选.
而这个时候为了加快查询速度, 索引就出现了, 索引是针对少量特定字段的值拿出来进行排序存储, 并记录在表中的位置, 
而因为索引是有序的, 所以就会很容易通过索引查询到具体的记录位置, 然后再根据记录位置直接从表中读取该记录.
同时因为索引的字段较少, 所以索引通常会比其基表小得多.
从上面通过索引访问表记录的方式可以看出, 当要访问的数据量较大时, 通过每一条记录的位置去访问原始记录, 
每一条符合条件的记录都需要经过索引访问后再访问基表这样一个复杂的过程, 这会花费很多时间,
同样, 如果不经过索引而直接查询表, 也可能因为表字段太多, 记录较大的情况下把全部的数据读取进来, 这也会花费很多时间.
那怎么办呢?
这个时候就会想到, 如果表中数据本身就是有序的, 这样查询表的时候就可以快速的找到符合条件的记录位置, 
而很容易判断符合条件记录的位置, 这样只需要读取一小部分数据出来就可以了, 不需要全表记录都读取出来进行判断.
索引表就这样产生了.当然索引表中插入,更新资料的时候可能会因为需要排序而将数据重组, 这时候数据插入或更新速度会比堆组织表慢一些.
如果堆组织表上有索引, 那么对堆组织表的插入也会因为要修改索引而变慢

虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。

第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。
第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。

了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。

最左前缀原理与相关优化
主索引为<emp_no, title, from_date>
情况一：全列匹配。
SELECT * FROM employees.titles WHERE emp_no='10001' AND title='Senior Engineer' AND from_date='1986-06-26'; √
SELECT * FROM employees.titles WHERE from_date='1986-06-26' AND emp_no='10001' AND title='Senior Engineer'; √
当按照索引中所有列进行精确匹配（这里精确匹配指“=”或“IN”匹配）时，索引可以被用到。这里有一点需要注意，理论上索引对顺序是敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引，例如我们将where中的条件顺序颠倒效果是一样的。

情况二：最左前缀匹配。
SELECT * FROM employees.titles WHERE emp_no='10001'; √
当查询条件精确匹配索引的左边连续一个或几个列时，如<emp_no>或<emp_no, title>，所以可以被用到，但是只能用到一部分，即条件所组成的最左前缀。上面的查询从分析结果看用到了PRIMARY索引，但是key_len为4，说明只用到了索引的第一列前缀。

情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供。
SELECT * FROM employees.titles WHERE emp_no='10001' AND from_date='1986-06-26'; √
此时索引使用情况和情况二相同，因为title未提供，所以查询只用到了索引的第一列，而后面的from_date虽然也在索引中，但是由于title不存在而无法和左前缀连接，因此需要对结果进行扫描过滤from_date（这里由于emp_no唯一，所以不存在扫描）。如果想让from_date也使用索引而不是where过滤，可以增加一个辅助索引<emp_no, from_date>，此时上面的查询会使用这个索引。除此之外，还可以使用一种称之为“隔离列”的优化方法，将emp_no与from_date之间的“坑”填上。
 SELECT * FROM employees.titles
WHERE emp_no='10001'
AND title IN ('Senior Engineer', 'Staff', 'Engineer', 'Senior Staff', 'Assistant Engineer', 'Technique Leader', 'Manager')
AND from_date='1986-06-26';

情况四：查询条件没有指定索引第一列。
SELECT * FROM employees.titles WHERE from_date='1986-06-26'; ×

情况五：匹配某列的前缀字符串。 
SELECT * FROM employees.titles WHERE emp_no='10001' AND title LIKE 'Senior%'; √

情况六：范围查询。
SELECT * FROM employees.titles WHERE emp_no < '10010' and title='Senior Engineer'; √
范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。

情况七：查询条件中含有函数或表达式。
SELECT * FROM employees.titles WHERE emp_no='10001' AND left(title, 6)='Senior'; ×
很不幸，如果查询条件中含有函数或表达式，则MySQL不会为这列使用索引（虽然某些在数学意义上可以使用）

InnoDB的主键选择与插入优化(存疑？)

在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。

经常看到有帖子或博客讨论主键选择问题，有人建议使用业务无关的自增主键，有人觉得没有必要，完全可以使用如学号或身份证号这种唯一字段作为主键。不论支持哪种论点，大多数论据都是业务层面的。如果从数据库索引优化角度看，使用InnoDB引擎而不使用自增主键绝对是一个糟糕的主意。

上文讨论过InnoDB的索引实现，InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。

如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。
这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。

如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。





MySQL技术内幕:InnoDB存储引擎

数据库：是物理操作系统文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合，在MYSQL数据库中，数据库文件可以是frm、MYD、MYI、ibd结尾的文件
数据库实例：是一个程序，是位于用户和操作系统之间的一层数据管理软件，用户对数据库数据的任何操作，包括数据库定义、数据查询、数据维护、数据库运行控制等都是在数据库实例下进行的，应用程序只有通过数据库实例才能和数据库打交道，它由后台线程以及一个共享内存区组成，数据库实例才是真正用于操作数据库文件的

数据库是由一个个文件（一般来说都是二进制文件）组成的，要对这些文件执行诸如SELECT、INSERT、UPDATE之类的数据库操作是不能通过简单的操作文件来更改数据库的内容，需要通过数据库实例来完成对数据库的操作

在MYSQL数据库中，实例与数据库的关系通常是一一对应的，即一个实例对应一个数据库，在集群情况下可能存在一个数据库被多个数据实例使用的情况

MYSQL被设计为一个单进程多线程架构的数据库，与SQL Server类似，但与Oracle多进程的架构不同


							  MYSQL体系结构

							连接方（JDBC、ODBC）

						连接池（鉴权、连接限制、内存检查）

	  SQL接口（DML、DDL、存储过程、触发器）   解析器      分析器        缓存	

	        插件式存储引擎（内存、索引、存储管理）（MyISAM、InnoDB）	

	          文件系统                      文件和日志（redo、undo）


InnoDB存储引擎
支持事务，其设计目标主要面向在线事务处理的应用。其特点是行锁设计、支持外键，并支持类似于Oracle的非锁定读，即默认读取操作不会产生锁。从MYSQL5.5.8开始，就是默认的存储引擎
InnoDB通过使用多版本并发控制（MVCC）来获得高并发性，并且实现了SQL标准的4种隔离级别，同时，使用一个被称为next-key locking的策略来避免幻读现象的产生
对于表中数据的存储，InnoDB存储引擎采用了聚集的方式，因此每张表的存储都是按主键的顺序进行存放，如果没有显式地在表定义时指定主键，InnoDB存储引擎会为每一行生成一个6字节的ROWID，并以此作为主键

MYISAM存储引擎
不支持事务、表锁设计，支持全文索引，主要面向一些OLAP数据库应用，此外，它的缓冲池只缓存索引文件，而不缓冲数据文件，这点和大多数的数据库都不同

NDB存储引擎
join操作是在MYSQL数据库层完成的，而不是在存储引擎层完成的，这意味着，复杂的连接操作需要巨大的网络开销，因此查询速度很慢

Memory存储引擎
将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据都将消失，默认使用哈希索引，而不是B+树索引，存储变长字段varchar时是按照定长字段（char）的方式进行的

连接MYSQL操作是一个连接进程和mysql数据库实例（也是一个进程）进行通信，本质上是进程间的通信，常用的进程通信方式有管道、TCP/IP、UNIX域套接字，mysql数据库提供的连接方式从本质上看都是上述提及的进程通信方式

TCP/IP是网络中使用的最多的一种数据库连接方式，这种方式在TCP/IP连接上建立一个基于网络的连接请求，一般情况下客户端在一台服务器，而mysql实例在另一台服务器上，这两台机器通过一个TCP/IP网络连接


InnoDB存储引擎
是事务安全的MYSQL存储引擎，设计上采用了类似于Oracle数据库的架构，通常来说，InnoDB存储引擎是OLTP应用中核心表的首选存储引擎
是第一个完整支持ACID事务的MYSQL存储引擎

InnoDB存储引擎有多个内存块，可以认为这些内存块组成了一个大的内存池，负责如下工作：
维护所有线程需要访问的多个内部数据结构
缓存磁盘上的数据，方便快速地读取，同时在对磁盘文件的数据修改之前在这里缓存
redo log 缓存

后台线程 后台线程 后台线程 后台线程 后台线程

		InnoDB存储引擎内存池

		     数据库文件

后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存是最新的数据，此外将已修改的数据文件刷新到磁盘文件
多个不同的后台线程，负责处理不同的任务

Master Thread
是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新，合并插入缓冲，UNDO页的回收

IO Thread
在InnoDB存储引擎中大量使用了AIO来处理写IO请求，这样可以极大提高数据库的性能。而IO Thread的工作主要是负责这些IO请求的回调处理

Purge Thread
事务被提交后，其所使用的undolog可能不再需要，因此需要PurgeThread来回收已经使用并分配的undo页


内存
缓冲池
InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此可将其视为基于磁盘的数据库系统，由于CPU速度与磁盘速度之间的鸿沟，基于磁盘的数据库系统通常使用缓冲池技术来提高数据库的整体性能
缓冲池简单来说就是一块内存区域，在数据库中进行读取页的操作，首先将从磁盘读到的页存放在缓冲池中，这个过程称为将页FIX在缓冲池中。下一次再读取相同的页时，首先判断该页是否在缓冲池中，若在，称该页在缓冲池中被命中，直接读取该页
对于数据库中页的修改操作，则首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上，但刷新的操作并不是在每次页更新时触发，而是通过一种称为CheckPoint的机制回刷磁盘
缓冲池的大小直接影响着数据库的整体性能

缓冲池：数据页、索引页、插入缓冲、锁信息、自适应哈希索引、数据字典信息
重做日志缓冲

允许有多个缓冲池实例，每个页根据哈希值平均分配到不同缓冲实例中
数据库中的缓冲池是通过LRU（Latest Recent Used最近最少使用）算法来进行管理的，最频繁使用的页在LRU列表的前端，反之在后端，当缓冲池不能存放读取到的页时，将首先释放后端的页
InnoDB缓冲池中页的大小默认为16KB

在LRU列表中的页被修改后，称该页为脏页，即缓冲池中的页和磁盘上的页数据产生了不一致，这时数据库会通过CheckPoint机制将脏页刷新回磁盘，Flush列表中的页即为脏页列表。需要注意的是，脏页即存在于LRU列表中，也存在于Flush列表中，LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘。两者互不影响

重做日志缓冲
InnoDB存储引擎首先将重做日志信息先放入到这个缓冲区，然后按一定频率将其刷新到重做日志文件，重做日志缓冲一般不需要设置得很大，因为一般情况下每一秒会将重做日志缓冲刷新到日志文件，因此用户只需要保证每秒产生的事务量在这个缓冲大小之内即可

在通常情况下，8MB的重做日志缓冲池足以满足绝大部分的应用，重做日志在下列三种情况下会将重做日志缓冲回刷到磁盘的重做日志文件中
1.Master Thread每一秒将重做日志缓冲刷新到重做日志文件
2.每个事务提交时
3.当重做日志缓冲池剩余空间小于1/2时

CheckPoint技术

缓冲池的设计目的为了协调CPU速度与磁盘速度的鸿沟，因此页的操作首先都是在缓冲池中完成的，如果一条DML语句，如update或delete改变了页中的记录，那么此时页是脏的，即缓冲池中的页的版本要比磁盘的新，数据库需要将新版本的页从缓冲池刷新到磁盘
倘若每次一个页发生变化，就将新页的版本刷新到磁盘，那么这个开销是非常大的。若热点数据集中在某几个页中，那么数据库的性能将变得非常差，同时，如果在缓冲池将页的新版本刷新到磁盘时发生了宕机，那么数据就不能恢复了。为了避免发生数据丢失问题，当前事务数据库系统普遍都采用了Write Ahead Log策略，即当事务提交时，先写重做日志，再修改页。当由于发生宕机而导致数据丢失时，通过重做日志来完成数据的恢复，这也是事务ACID中D的要求

思考下面的场景，如果重做日志可以无限地增大，同时缓冲池也足够大，能够缓冲所有数据库的数据，那么是不需要将缓冲池中页的新版本刷新回磁盘。因为当发生宕机时，完全可以通过重做日志来恢复整个数据库系统中的数据到宕机发生时刻，但是这需要两个前提条件：
1缓冲池可以缓存数据库中的所有数据
2重做日志可以无限增大
对于第一点，当前3TB的MYSQL数据库以并不少见，但是3TB的内存却非常少见
对于第二点，重做日志可以无限增大，但是重做日志越大，宕机后数据库的恢复时间就越长，恢复的代价会越来越大
因此CheckPoint检查点技术的目的是解决以下几个问题：
缩短数据库的恢复时间
缓冲池不够用时，将脏页刷新到磁盘
重做日志不可用时，刷新脏页
当数据库发生宕机时，数据库不需要重做所有日志，因为CheckPoint之前的页都已经刷新回磁盘，只需对检查点之后的重做日志进行恢复
当缓冲池不够用时，根据LRU算法会移除最近最少使用的页，若此页为脏页，那么需要强制执行CheckPoint，将脏页数据回刷
重做日志出现不可用的情况是因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是让其无限增大的，

在InnoDB存储引擎中，检查点发生的时间、条件及脏页的选择都非常复杂，其所做的事情无外乎是将缓冲池的数据回刷
检查点分为以下两种
Sharp CheckPoint
Fuzzy CheckPoint
Sharp检查点发生在数据库关闭时将所有的脏页都刷回磁盘
数据库在运行时使用Fuzzy检查点，即只刷新一部分脏页
对于Master Thread中发生的检查点，差不多以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘，这个过程是异步的，用户查询线程不会阻塞
检查点既会发生在LRU列表也会发生在脏页列表

Master Thread工作方式
InnoDB存储引擎的主要工作都是在一个单独的后台线程Master Thread中完成的
Master Thread具有最高级别优先级，其内部由多个循环组成：主循环、后台循环、刷新循环、暂停循环，根据数据库运行状态进行切换
主循环每秒或者每10秒进行一次操作
每秒一次的操作包括：
1.日志缓冲刷新到磁盘，即使这个事务还没有提交
2.合并插入缓冲
3.至多刷新100个InnoDB脏页到磁盘
即时某个事物还没有提交，InnoDB存储引擎仍然每秒会将重做日志缓冲中的内容刷新到重做日志文件
若当前没有用户活动，就会切换到后台循环，后台循环执行以下操作：
1.删除无用的Undo页
2.合并20个插入缓冲
3.跳回主循环

InnoDB关键特性

插入缓冲
两次写
自适应哈希索引
异步IO
刷新邻接页

插入缓冲

insert buffer可能是InnoDB存储引擎关键特性中最令人激动和兴奋的一个功能
插入缓冲和数据页一样，也是物理页的一个组成部分
在InnoDB存储引擎中，主键是行唯一的标识符，通常应用程序中行记录的插入顺序是按照主键递增的顺序进行插入的，因此，插入聚集索引一般是顺序的，不需要磁盘的随机读取
注意：并不是所有的主键插入都是顺序的，若主键类是UUID或者自增主键插入了指定的值，那么可能会导致插入不连续的情况

但是不可恩每张表上只有一个聚集索引，更多情况下，一张表上有多个非聚集的辅助索引，如下：
CREATE TABLE t {
	a INT AUTO_INCREMENT,
	b VARCHAR(30),
	PRIMARY KEY(a),
	key(b)
};
在进行插入操作时，数据页的存放还是按主键a顺序存放的，但是对于非聚集索引叶子节点的插入不再是顺序的了，这时就需要离散地访问非聚集索引页，由于随机读取的存在而导致了插入操作性能下降，当然这并不是这个b字段上索引的错误，而是因为B+树的特性决定了非聚集索引插入的离散性
对此，InnoDB存储引擎开创性地设计了Insert Buffer，对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入，若不在，则先放入到一个Insert Buffer对象中，好似欺骗数据库这个非聚集索引已经插入到叶子节点，而实际并没有，只是存放在另一个位置，然后再以一定的频率和情况进行Insert Buffer和辅助索引页子节点的merge操作，这时通常能够将多个插入合并到一个操作中（因为在一个索引页中），这就大大提高了对于非聚集索引插入的性能

Insert Buffer的使用需要同时满足以下两个条件：
索引是辅助索引
索引不是唯一的
若应用程序进行大量的插入操作，这些都涉及了不唯一的非聚集索引，也就是使用了Insert Buffer，若此时MYSQL数据库发生了宕机，会有大量的插入缓冲并没有合并到实际的非聚集索引中去，因此这时恢复可能需要很长的时间
辅助索引不能是唯一的，因为在插入缓冲时，数据库并不去查找索引页来判断插入记录的唯一性，这个判断比较耗费性能

目前插入缓冲存在的一个问题是，在写密集的情况下，插入缓冲会占用过多的缓冲池内存，默认最大可以占用到1/2的缓冲池内存

change buffer
insert buffer的升级，InnoDB存储引擎可以对DML操作——Insert、Delete、Update都进行缓冲，分别是Insert Buffer、Delete Buffer、Purge Buffer
change buffer适用的对象依然是非唯一的辅助索引

Insert Buffer的内部实现
Insert Buffer的数据结构是一颗B+树，在MYSQL4.1之间的版本中每张表有一棵Insert Buffer B+树，现在的版本中，全局只有一棵，负责对所有的表辅助索引进行Insert Buffer
Insert Buffer是一棵B+树，因此其也由叶子节点和非叶节点组成，非叶节点存放的是查询的search key，其构造如下：
space + marker + offset
space表示待插入记录所在表的表空间id，在InnoDB存储引擎中，每张表有一个唯一的space id，marker用来兼容老版本，offset表示页所在的偏移量

当一个辅助索引要插入到页时，如果这个页不在缓冲池中，那么该索引会先插入到insert buffer中，插入之前，InnoDB存储引擎首先根据上述规则构造一个search key，接下来查询Insert Buffer这棵树，然后再将这条记录插入叶子节点中

因为启用Insert Buffer索引后，辅助索引页中的记录可能被插入到Insert Buffer B+树中，所以为了保证每次Merge Insert Buffer页必须成功，还需要有一个特殊的页用来标记每个辅助索引页的可用空间，这个页的类型为Insert Buffer Bitmap

Merge Insert Buffer
辅助索引从Insert Buffer合并到真正的索引中可能发生在以下几种情况下：
1.辅助索引页被读取到缓冲池时
2.Insert Buffer Bitmap页追踪到该辅助索引页已无可用空间时
3.Master Thread
第一种情况例如在执行Select时，需要检查该辅助索引页是否有记录存放于Insert Buffer B+树中，若有，则将Insert Buffer B+树中该页的记录插入到该辅助索引页中，而且如果该页有多次插入则会被合并为一次操作
Insert Buffer Bitmap页用来追踪每个辅助索引页的可用空间，并至少有1/32页的空间，若检测后发现空间不足1/32，则会进行一次强制合并操作
Master Thread线程每秒或每10秒会进行一次Merge Insert Buffer操作，并且执行merge操作的不止一个页


两次写
double write带给InnoDB存储引擎的是数据页的可靠性

当数据库发生宕机时，可能InnoDB存储引擎正在写入某个页到表中，而这个页只写了一部分，比如16KB的页，只写了前4KB，之后发生了宕机，这种情况被称为部分写失效，这是该页的数据是被损坏的（可能一条记录部分字段是对的，部分字段是错的）
如果写失效，可以通过重做日志进行恢复，但是重做日志记录的是对页的物理操作，如果这个页本身已经发生了损坏，再对其进行重做是没有意义的。这就是说，在应用重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是doublewrite
doublewrite由两部分组成，一部分是内存中的doublewrite buffer，大小为2MB，另一部分是物理磁盘上共享表空间中连续128个页，大小同样为2MB
在对缓冲池的脏页进行刷新时，并不直接写磁盘，而是将脏页先复制到内存中的doublewrite buffer，之后分两次写入物理磁盘
参数skip_innodb_doublewrite可以禁止使用doubleWrite功能，不过，对于需要提供数据高可靠性的服务器，任何时候用户都应该开启doubleWrite功能


自适应哈希索引
哈希的查找时间复杂度为O(1)，B+树的复杂度取决于树的高度，在生产环境中，高度一般为3~4层
InnoDB存储引擎会监控对表上各索引页的查询，如果观察到建立哈希索引可以带来速度提升，则建立哈希索引，称之为自适应哈希索引AHI

AHI是通过缓冲池的B+树页构造而来，因此建立的速度很快，而且不需要对整张表构建哈希索引，InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引

哈希索引只能用来搜索等值的查询，对于其他查找类型，如范围查找，是不能使用哈希索引的

异步IO
用户在发出一个IO请求之后立即再发出另一个IO请求，当全部IO请求发送完毕后，等待所有IO操作的完成

启动、关闭与恢复
参数innodb_fast_shutdown控制数据库正常关闭时的行为 0表示需要完成所有当前任务再关闭 1刷新脏页后就关闭 2写入日志后就关闭
innodb_force_recovery控制数据库启动时的行为 3表示不进行事务的回滚操作


数据库文件
参数文件：告诉MYSQL实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数
日志文件：错误日志，二进制日志、查询日志
socket文件：当用UNIX域套接字方式进行连接时需要的文件
Pid文件：MYSQL实例的进程ID文件
MYSQL表结构文件：用来存放MYSQL表结构定义文件
存储引擎文件：每个存储引擎都会有自己的文件来保存各种数据

MYSQL数据库的参数文件是以文本方式进行存储的，用户可以直接通过一些常用的文本编辑软件进行参数的修改
可以通过命令SHOW VARIABLES查看数据库中的所有参数

慢查询日志文件

可以在MYSQL启动时设一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询日志文件中，通过参数long_query_time来设置，默认值10，代表10秒

打开log_queries_not_using_indexes参数设置，如果运行的SQL语句没有使用索引则记录到慢查询日志文件

物理读是指从磁盘进行IO读取的次数，逻辑读包含所有的读取，不管是磁盘还是缓冲池
通过参数long_query_io将超过指定逻辑IO次数的SQL语句记录到slow log中


查询日志
查询日志记录了所有对mysql数据库请求的信息，无论这些请求是否得到了正确的执行

二进制日志

二进制日志记录了对MYSQL数据库执行更改的所有操作，但是不包括select和show这类操作，因为这类操作对数据本身并没有修改，然而，若操作本身并没有导致数据库发生变化，该操作可能也会写入二进制日志
如果用户想记录SELECT和SHOW操作，那只能使用查询日志，而不是二进制日志
二进制日志主要有以下几种作用：

恢复：某些数据的恢复需要二进制日志

复制：通过复制和执行二进制日志使一台远程的MYSQL（slave）数据库与另一台MYSQL数据库（master）进行实时同步

审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入的攻击
审计（事前审计，事后审计）
开启二进制日志的确会影响性能，但是性能的损失十分有限，根据MYSQL官方手册中的测试表明，开启二进制日志会使性能下降1%，但考虑到可以使用复制和point-in-time的恢复，这些性能损失绝对是可以且应该被接受的

在默认情况下，二进制日志并不是在每次写的时候同步到磁盘，当数据库宕机时，可能会有最后一部分数据没有写入文件中，参数sync_binlog=N表示每写缓冲多少次就同步到磁盘，N=1时表示采用同步写磁盘的方式，不过此时会对数据库的IO带来一定的影响

如果当前数据库是复制中的slave角色，则它不会将从master取得并执行的二进制日志写入自己的二进制日志文件中去。如果需要写入，要设置log-slave-update。如果需要搭建主从架构，则必须设置该参数

binlog_format参数十分重要，它影响了记录二进制日志的格式，在MYSQL5.1版本之前，没有这个参数，所有二进制文件的格式都是基于SQL语句级别的，对于复制是有一定要求的，如在主服务器运行rand、uuid等函数，又或者使用触发器等操作，这些都可能会导致主从服务器上表中数据的不一致，另一个影响是，会发现InnoDB存储引擎的默认事务隔离级别是REPEATABLE READ，这其实也是因为二进制日志文件格式的关系，如果使用READ COMMITTED的事务隔离级别（大多数数据库，如oracle，sql server的默认隔离级别），会出现类似丢失更新的现象，从而出现主从数据库上的数据不一致

MYSQL5.1开始引入了binlog_format参数，该参数可设的值有STATEMENT、ROW和MIXED
1.STATEMENT格式和之前的MYSQL版本一样，记录的是SQL语句日志
2.在ROW格式下，记录的是表行的更改情况，如果设置了binlog_format为ROW，可以将InnoDB的事务隔离级别设为READ COMMITED，以获得更好的并发性

二进制日志文件的文件格式为二进制，不能像错误日志文件、慢查询日志文件那样用cat head tail等命令查看，要查看二进制日志文件的内容，必须通过MYSQL提供的工具mysqlbinlog


表结构定义文件
因为mysql插件式存储引擎的体系结构的关系，mysql数据的存储是根据表进行的，每个表都会有与之对应的文件，但不论表采用何种存储引擎，mysql都有一个以fm为后缀名的文件，这个文件记录了该表的表结构定义


InnoDB存储引擎文件
之前介绍的文件都是mysql数据库本身的文件，和存储引擎无关，除了这些文件外，每个表存储引擎还有其自己独有的文件，比如重做日志文件，表空间文件

InnoDB采用将存储的数据按表空间进行存放的设计，对不同的表可以分配单独的表空间，单独的表空间文件仅存储该表的数据、索引、和插入缓冲等信息，其余信息还是存放在默认的表空间中

重做日志文件对于InnoDB存储引擎至关重要，它们记录了对于InnoDB存储引擎的事务日志，当实例失败时，重做日志文件就能派上用场，例如，数据库由于所在主机掉电导致实例失败，InnoDB存储引擎会使用重做日志恢复到掉电前的时刻，以此来保证数据的完整性
重做日志文件的大小设置对于InnoDB存储引擎的性能有着非常大的影响，一方面重做日志文件不能设置得太大，否则在恢复时可能需要很长的时间，但又不能太小，否则会导致一个事务的日志需要多次切换重做日志文件，还会导致频繁地发生async checkpoint，导致性能的抖动

重做日志与二进制日志有什么区别？
二进制日志会记录所有与mysql数据库有关的日志记录，包括各个存储引擎的日志，而InnoDB存储引擎的重做日志只记录有关该存储引擎本身的事务日志。
二进制日志记录的是关于一个事务的具体操作内容，即该日志是逻辑日志，redo log记录的是关于每个页的更改的物理情况
写入的时间也不同，二进制日志文件仅在事务提交前进行写入，即只写磁盘一次，不论这时该事务多大，而在事务进行的过程中，却不断有重做日志被写入
为了保证事务的ACID中的持久性，必须将redo log中innodb_flush_log_at_trx_commit设置为1，每当事务提交时，就必须确保事务都已经写入重做日志文件，那么当数据库因为意外发生宕机时，可以通过重做日志文件恢复，并保证可以恢复已经提交的事务

数据库表结构
表空间（单表空间，共享表空间） -> 段 -> 区 -> 页 -> 行 -> 字段

页
页是InnoDB磁盘管理的最小单位，默认每个页大小为16KB，可以通过参数innodb_page_size将页的大小设置为4K，8K，16K，一旦设置完成不可以再次修改

行
每个页最多允许存放7992行记录
行溢出数据
InnoDB存储引擎可以将一条记录中的某些数据存储在真正的数据页面之外，一般认为BLOB、LOB这类大对象列类型的存储会把数据存放在数据页面之外，但是，这个理解有些偏差，BLOB可以不将数据放在溢出页面，VARCHAR依然可能被存放为行溢出数据

VARCHAR
理论上MYSQL数据库VARCHAR类型可以存放65535字节，实际最多存放65532的长度，对于用户来说VARCHAR（N）中N指的是字符的长度，而文档中说明VARCHAR类型最大支持65535，单位是字节，此外需要注意的是，mysql官方手册中定义的65535长度是指所有VARCHAR列的长度总和，如果列的长度总和超出，依然无法创建
InnoDB存储引擎页的大小为16KB，即16384字节，一般情况下，InnoDB存储引擎的数据都是存放在页类型为B-tree node中，但是当发生行溢出时，数据存放在页类型为Uncompress BLOB页中

InnoDB存储引擎表是索引组织的，即B+tree的结构，这样每个页中至少应该有两条记录，如果页中只能存放下一条记录，那么InnoDB存储引擎会自动将行数据存放到溢出页中

从MYSQL4.1版本开始，CHAR（N）中的N是指字符的长度，而不是之前版本的字节长度

InnoDB数据页由以下7个部分组成
File Header 文件头 存储页的偏移值，上一个下一个页，所属表空间，页类型等
Page Header 页头 所处B+ tree层数，事务Id等
Infimun 和 Supremun Records 最大和最小的两条虚拟记录，在页创建时被建立，在任何情况下都不会被删除
User Records 实际存储数据的空间
Free Space 空闲空间
Page Directory 存放记录的相对位置
File Trailer 为了检测是否已经完整地写入磁盘


约束
关系型数据库系统和文件系统一个不同点是，关系数据库本身能保证存储数据的完整性，不需要应用程序的控制
对于InnoDB而言，提供了以下几种约束
Primary Key
Unique Key
Foreign Key
Not Null

分区表
分区功能并不是在存储引擎层完成的，因此不是只有InnoDB存储引擎支持分区，但也不是所有的存储引擎都支持
分区的过程是将一个表或索引分解为多个更小、更可管理的部分。就访问数据库的应用而言，从逻辑上讲，只有一个表或一个索引
MYSQL数据库支持的分区类型为水平分区，且是局部分区索引，一个分区中既存放了数据又存放了索引，
分区可能会给某些SQL语句性能带来提高，但是分区主要用于数据库高可用性的管理
当前mysql支持以下分区：
RANGE分区：行数据基于属于一个给定连续区间的列值被放入分区
LIST分区：和RANGE类似，只是LIST面向的是离散的值
HASH分区：根据用户自定义的表达式返回值来进行分区
KEY分区：根据MYSQL数据库提供的哈希函数来进行分区

如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分

查看表在磁盘上的物理文件，启用分区之后，表不再由一个ibd文件组成了，而是由建立分区时的各个分区ibd文件组成

分区的条件是：数据必须是整型，但mysql5.5版本开始支持非整型数据分区


mysql数据库允许对NULL值做分区。但是处理的方法与其他数据库可能完全不同，mysql数据库的分区总是视NULL值小于任何一个非NULL值，这和mysql数据库中处理NULL值的order by操作是一样的

分区和性能
数据库的应用分为两类：一类是OLTP（在线事务处理），如Blog、电子商务等，另一类是OLAP（在线分析处理），如数据仓库
对于OLAP的应用，分区的确是可以很好地提高查询的性能，因为OLAP应用大多数查询需要频繁扫描一张很大的表，然而对于OLTP的应用，分区应该非常小心，在这种应用下，通常不可能会获取一张大表中10%的数据，大部分都是通过索引返回几条记录即可，而根据B+树索引的原理可知，对于一张大表，一般的B+树需要2-3次的磁盘IO，因此B+树可以很好地完成操作，不需要分区的帮助。
很多开发团队会认为含有1000w行的表是一张非常巨大的表，所以往往采用分区，但100W和1000W行的数据本身构成的B+树的层次可能都是一样。而且如果不通过分区字段查询时，就需要扫描所有分区，假设有10个分区，即时每个分区查询开销为2次IO，则一共需要20次IO

即时是根据自增长主键进行的HASH分区也不能保证分区数据的均匀。因为插入的自增长ID并非总是连续的，如果该主键值因为某种原因被回滚了，则该值将不会再次被自动使用

索引
索引是应用程序设计和开发的一个重要方面，若索引太多，应用程序的性能可能会受到影响，而索引太少，对查询性能又会产生影响，要找到一个合适的平衡点，这对应用程序的性能至关重要

InnoDB存储引擎支持以下几种常见的索引
B+树索引
全文索引
哈希索引

InnoDB存储引擎支持的哈希索引是自适应的，InnoDB存储引擎会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引
B+树索引就是传统意义上的索引，这是目前关系型数据库系统中查找最为常用和最为有效的索引。注意B+树中的B不是代表二叉（binary），而是代表平衡（balance），因为B+树是从最早的平衡二叉树演化而来，但是B+树不是一个二叉树

不管怎么变化，B+树总是会保持平衡。但是为了保持平衡对于新插入的键值可能需要做大量的拆分页操作。因为B+树结构主要用于磁盘，页的拆分意味着磁盘的操作，所以应该在可能的情况下尽量减少页的拆分操作，因此，B+树同样提供了类似于平衡二叉树的旋转功能

InnoDB存储引擎表是索引组织表，即表中数据按照主键顺序存放。而聚集索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页，聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。同B+树数据结构一样，每个数据页都通过一个双向链表来进行链接

索引页中存放的仅仅是键值及指向数据页的偏移量
许多数据库的文档会这样告诉读者：聚集索引按照顺序物理地存储数据。但其实聚集索引的存储并不是物理上连续的，物理上的连续维护成本非常高，而是逻辑上连续的，除了页与页是通过双向链表链接，每个页中的记录也是通过双向链表进行维护的

辅助索引（非聚集索引）的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引来找到一个完整的记录

创建聚集索引
create CLUSTERED INDEX 索引名称 ON 表名(字段名)

创建非聚集索引
create NONCLUSTERED INDEX 索引名称 ON 表名(字段名)

如果没有显示的指定聚集索引，InnoDB会默认在主键上建立聚集索引，如果没有主键则选择第一个不为空的唯一索引作为聚集索引，如果都没有则隐式的创建一个聚集索引

对于其他的一些数据库，如SQL Server和Oracle，其有一种称为堆表的类型，即行数据的存储按照插入的顺序存放。这与MYSQL数据库的MyISAM存储引擎有些类似，堆表的特性决定了堆表上的索引都是非聚集的，主键与非主键的区别只是是否唯一且非空，因此这时书签是一个行标识符，可以用如“文件号：页号：槽号”的格式来定位实际的行数据
堆表的书签使非聚集查找可以比主键书签方式更快，并且非聚集可能在一张表中存在多个，对于非聚集索引的离散读取，索引组织表上的非聚集索引会比堆表上的聚集索引慢一些，但是一般的数据库都通过实现预读技术来避免多次的离散读操作

MYSQL5.5版本之前对于索引的添加或者删除这类DDL操作，操作过程为：
首先创建一张新的临时表，表结构为通过命令ALTER TABLE新定义的结构
然后把原表的数据导入到临时表
接着删除原表
最后把临时表重命名为原来的表
InnoDB存储引擎支持一种快速索引创建方式-简称FIC
对于辅助索引的创建，会对创建索引的表加上一个S锁，在创建的过程中，不需要重建表，速度可以提高很多，由于在索引的创建过程中对表加了S锁，因此在创建的过程中只能对该表进行读操作，此外FIC只限定于辅助索引，对于主键的创建和删除同样需要重建一张表

怎么查看索引是否是高选择性的呢？可以通过SHOW INDEX结果中的列Cardinality来观察，Cardinality是一个预估值，而不是一个准确值，在实际应用中，Cardinality/n_rows_in_table应尽可能地接近1，如果非常小，那么需要考虑是否还有必须创建这个索引

联合索引
联合索引也是一颗B+树，不同的是联合索引的键值的数量不是1，而是大于等于2

	                   p1 | (2,4) | p2 

   | (1,1) | (1,2) | (2,1) |    | (2,4) | (3,1) | (3,2) |

其实和之前讨论的单个键值的B+树并没有什么不同，键值都是排序的

覆盖索引
即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录（不需要回表）

强制索引
在某些情况下，优化器不会选择索引去查找数据，而是直接进行全表扫描来得到数据，这种情况多发生于范围查找，Join链接等情况
例如 Select * from order where orderId > 10000;
其中orderId字段有辅助索引，但是查询时却没有使用该索引
原因在于用户要选取的数据是整行信息，而orderId索引不能覆盖到我们要查询的信息，因此在对OrderId索引查询到指定数据后，还需要一次回表来查找整行数据的信息，虽然orderId索引中数据是顺序存放的，但是再一次进行回表查询的数据则是无序的，因此变为了磁盘上的离散读操作，如果要求访问的数据量很小，则优化器还是会选择辅助索引，但是当访问的数据占整个表中数据的蛮大一部分时（一般是20%），优化器会选择通过聚集索引来查找数据，因为，顺序度要远远快于离散读

若用户使用的磁盘是固态硬盘，随机读操作非常快，同时有足够的自信来确认使用辅助索引可以带来更好的性能，那么可以使用关键字FORCE INDEX来强制使用某个索引

索引提示
MYSQL数据库支持索引提示，显示地告诉优化器使用哪个索引，一下两种情况可能需要用到INDEX HINT：
mysql数据库的优化器错误地选择了某个索引，导致sql语句运行的很慢。这种情况在最新的mysql数据库版本中非常非常的少见，这时有经验的DBA或开发人员可以强制优化器使用某个索引，以此来提高SQL运行的速度

某SQL语句可以选择的索引非常多，这时优化器选择执行计划时间的开销可能会大于SQL语句本身，例如，优化器分析Range查询本身就是比较耗时的操作，这时DBA或开发人员分析最优的索引选择，通过Index Hint来强制使优化器不进行各个执行路径的成本分析。直接选择指定的索引来完成查询
使用方法：select * from t USE INDEX(a) where a=1 AND b=2;
索引提示只是给优化器一个建议，优化器并不一定会使用

Multi-Range Read优化（MRR优化）

Index Condition Pushdown(ICP) 优化
从mysql5.6开始支持，在mysql5.6之前，当进行索引查询时，首先根据索引来查找记录，然后再根据WHERE条件来过滤记录，在5.6之后，MYSQL数据库会在取出索引的同时，判断是否可以进行WHERE条件的过滤，也就是将WHERE的部分过滤操作放在了存储引擎层

全文索引
全文检索是将存储于数据库中的整本书或整篇文章中的任意内容信息查找出来的技术，它可以根据需要获得全文中有关章、节、段、句、词等信息，也可以进行各种统计和分析
从InnoDB 1.2版本开始，InnoDB开始支持全文索引
倒排索引
全文检索通常使用倒排索引来实现，倒排索引同B+树索引一样，也是一种索引结构，它在辅助表中存储了单词与单词自身在一个或多个文档中所在位置之间的映射，这通常利用关联数组实现，其有两种形式：
inverted file index 表现形式为{单词，单词所在文档的ID}
full inverted index 表现形式为{单词，（单词所在文档ID，在具体文档中的位置）}
InnoDB采用的是后面的方式，全文检索表中，有两个列，一个是word字段，另一个是ilist字段，ilist中存储文档和位置信息，存储信息的表称为辅助表，InnoDB中共有6张辅助表，并且是持久化的
全文检索语法
查询fts_a表body字段中带有Pease的数据
Select * from fts_a where MATCH(body) AGAINST('Pease')
若表没有创建倒排索引，则执行MATCH函数会抛错
创建全文索引
CREATE TABLE articles (
	id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
	title VARCHAR(200),
	body TEXT,
		FULLTEXT(title,body)
) ENGINE=InnoDB;

数据库锁
开发多用户、数据库驱动的应用时，最大的一个难点就是：一方面要最大程度地利用数据库的并发访问，另一方面还要确保每个用户能以一致的方式读取和修改数据，为此就有了锁机制，同时这也是数据库系统区别于文件系统的一个关键特性，InnoDB存储引擎较之MYSQL数据库的其他引擎在这方面做得更好，其实现方式非常类似于Oracle

不同数据库，不同存储引擎之间锁的实现机制都是不一样的
lock的对象是事务，用来锁定的是数据库中的对象，如表、页、行，并且一般lock的对象仅在事务commit或rollback后进行释放
mysql为了满足事务的隔离性（事务与事务之间互不影响，在提交之前，对其他事务不可见），必须在commit或rollback之后才能释放锁

锁的类型
InnoDB实现了如下两种标准的行级锁：
共享锁（S Lock）允许事务读一行数据
排他锁（X Lock）允许事务删除或更新一行数据
如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立刻获得行r的共享锁，因为读物并没有改变行r的数据，称这种情况为锁兼容。若有其他的事务T3想获得行r的排它锁，则其必须等待事务T1,T2释放行r上的共享锁，这种情况称为锁不兼容
X锁与任何锁都不兼容，而S锁仅和S锁兼容，这个兼容指的是对同一数据行的兼容
此外，InnoDB存储引擎支持多粒度锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在，为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为意向锁。意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度上进行加锁
若将上锁的对象看成一颗树，那么对最下层的对象上锁，也就是对最细粒度的对象进行上锁，那么首先需要对粗粒度的对象上锁，如果需要对页上的记录r上X锁，那么分别需要对数据库A、表、页上意向锁IX，最后对记录r上X锁，若其中任何一个部分导致等待，那么该操作需要等到粗粒度锁的完成。
假如在事务T1对记录r加X锁之前，已经有事务T2对表1加了S表锁，由于事务T1需要对记录r在表1上加上IX锁，导致不兼容
InnoDB支持意向锁设计比较简练，其意向锁即为表级别的锁，设计目的主要是为了在一个事务中揭示下一行将被请求的锁类型，支持两种意向锁：
意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁
意向排他锁（IX Lock），事务想要获得一张表中某几行的排它锁
由于InnoDB存储引擎支持的是行级别的锁，因此意向锁其实不会阻塞除全表扫以外的任何请求，意向锁与意向锁之间都是相互兼容，意向锁与普通锁的兼容性 和 普通锁之间的兼容性一致
例如：DDL操作锁表与行数据update之间不兼容，意向锁的存在使得数据库在判断是否加锁时更快速

		    数据库A
				
   表1        表2        表3	

   页p        

   记录行r  

一致性非锁定读（快照读）
一致性的非锁定读是指InnoDB存储引擎通过行多版本控制的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放，相反地，InnoDB存储引擎会去读取行的一个快照数据
之所以称其为非锁定读，因为不需要等待访问的行上X锁的释放。快照数据是指该行的之前版本的数据，该实现是通过undo段来完成，而undo用来在事务中回滚数据，因此快照数据本身是没有额外的开销。此外，读取快照数据是不需要加锁的，因为没有事务需要对历史的数据进行修改操作
在事务隔离级别读已提交和可重复读下，InnoDB都是采用的快照读，然而，对于快照数据的定义却不一致，在读已提交下，总是读取被锁定行的最新一份快照数据，而在可重复读下，总是读取事务开始时的行数据版本

一致性锁定读
默认配置下，InnoDB对select操作使用一致性非锁定读（快照读），在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性，对select的只读操作，InnoDB有两种加锁方式：
SELECT...FOR UPDATE; 对行记录加一个X锁
SELECT...LOCK IN SHARE MODE 对行记录加一个S锁
这两条是显式的加锁语句，所以必须在一个事务中，当事务提交了，锁也就释放了，相对地，对于普通的update语句如果在事务中执行则会隐式的加上X锁，事务提交或回滚时释放，如果update不在事务中也会隐式加锁，只不过执行完就立即释放了

自增长与锁
插入操作会根据自增长的计数器值加1赋予自增长列，这个实现方式称做AUTO-INC Locking，这种锁其实是采用一种特殊的表锁机制，为了提高插入的性能，锁不是在一个事务完成后才释放，而是在完成对自增长值插入的SQL语句后立刻释放，但是并发插入的效率还是较差，对于INSERT...SELECT的大数据量插入影响更大
从MYSQL5.1开始，InnoDB提供了一种轻量互斥量的自增长实现机制，大大提高了插入的性能
另外，在InnoDB中，自增长的列必须是索引，同时必须是索引的第一个列，否则，会抛异常

锁的算法
InnoDB行锁的3种算法，也可以说是加锁的范围
Record Lock：单个行记录上的锁
Gap Lock：间隙锁，锁定一个范围，但不包含记录本身
Next-Key Lock：Gap Lock+Record Lock，临键锁，锁定一个范围，并且锁定记录本身
这三种锁都是行锁和排他锁，行锁在InnoDB中是基于索引实现的，所以一旦某个加锁操作没有使用索引，那么该锁就会退化为表锁

Record Lock总是会去锁住索引记录，如果InnovationDB存储引擎表在建立的时候没有设置任何一个索引，那么这时InnoDB存储引擎会使用隐式的主键来进行锁定
Next-Key Lock是结合了Gap Lock和Record Lock的一种锁定算法，这这种算法下，InnoDB对于行的查询都是采用这种锁定算法，其设计的目的是为了解决Phantom Problem幻读问题
假设一个索引有10,11,13和20这四个值，那么该索引可能被Next-Key Locking的区间为：
（-无穷,10]
(10,11]
(11,13]
(13,20]
(20,+无穷)
除了next-key locking还有previous-key locking技术

当查询的索引含有唯一属性时，next-key lock会降级为Record Lock

表z的列b是辅助索引，当当执行下面的sql语句：
select * from z where b=3 for update;
由于表中有两个索引，需要分别进行锁定，对于聚集索引，其仅对列a等于5的索引加上Record Lock，而对于辅助索引，其加上的是Next-Key Lock,锁定的范围是(1,3)，
还会对辅助索引下一个键值加上gap lock，即还有一个辅助索引范围为(3,6)的锁

Gap Lock的作用是为了阻止多个事务将记录插入到同一范围内，而这会导致幻象问题产生，加入上面的例子中，会话A中用户已经锁定了b=3的记录，若此时没有Gap Lock锁定(3,6)
，那么用户可以插入索引b列为3的记录

对于唯一键值得锁定，next-key lock降级为Record Lock仅存在于查询所有的唯一索引列。若唯一的索引由多个列组成，而查询仅是查找多个唯一索引列中的其中一个，那么查询其实是range类型查询，故InnovationDB存储引擎依然使用next-key lock进行锁定

Phantom Problem
在MySQL默认RR的隔离级别下，InnoDB存储引擎采用Next-Key Locking机制来避免幻象问题，这点不同于其他的数据库，如Oracle需要在Serializable的隔离级别下才能
解决幻象问题
幻象问题是指在同一事务下，连续执行两次同样的SQL语句可能导致不同的结果，第二次SQL语句可能会返回之前不存在的行
注意：InnoDB仅在RR隔离级别下采用Next-Key Locking，在READ COMMITTED下，只采用Record Lock，则不能解决幻象问题
多个事务并发对同一条记录执行select...lock in share mode，只有一个事务会成功，其余的会抛出死锁的错误

count（*）、count（1）和count（列名）
count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL  
count(1)包括了忽略所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL  
count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。

列名为主键，count(列名)会比count(1)快  
列名不为主键，count(1)会比count(列名)快  
如果表多个列并且没有主键，则 count（1） 的执行效率优于 count（*）  
如果有主键，则 select count（主键）的执行效率是最优的  
如果表只有一个字段，则 select count（*）最优。













