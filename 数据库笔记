数据库笔记

内连接查询，on条件是A表或者B表的唯一字段，则结果集是两表的交集，不是笛卡尔积。
假如，on条件是表中非唯一字段，则结果集是两表匹配到的结果集的笛卡尔积(局部笛卡尔积) 。


EXISTS 指定一个子查询，检测行的存在。语法：EXISTS subquery。参数 subquery 是一个受限的 SELECT 语句 （不允许有 COMPUTE 子句和 INTO 关键字）。结果类型为 Boolean，如果子查询包含行，则返回 TRUE。

NOT EXISTS 的作用与 EXISTS 正相反。如果子查询没有返回行，则满足 NOT EXISTS 中的 WHERE 子句。

按照连接池默认的配置MAX为6，一百台应用服务器连接一个MySQL ，所以会有600个连接落到数据库,按照一个请求的处理时间1ms的话， 那么一秒钟就能处理1000个请求， 600个连接的话可以处理60w的qps/tps请求了，这时候就已经远远超出单个DB的容量极限了。

数据库的连接都是附带状态的，事务的状态也是维持在连接上的，而一个连接在单位时间内只能处理一个事务请求， 所以需要多个连接来保证并发度，同时数据库（MySQL）也需要创建相应多的线程来绑定这个关系

InnoDB 行锁是通过给索引上的索引项加锁来实现的，这一点 MySQL 与 Oracle 不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB 这种行锁实现的特点意味着：只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁。

在实际应用中，要特别注意 InnoDB 行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。

1.在不通过索引条件查询的时候，InnoDB 确实使用的是表锁，而不是行锁。
2.由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，因此虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。应用设计的时候要注意这一点。
3.当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引还是普通索引，InnoDB 都会使用行锁来对数据加锁。
4.即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同的执行计划的代价来决定的。如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查 SQL 的执行计划，以确认是否真正使用了索引。

CHAR(M)定义的列的长度为固定的，M取值可以为0～255之间，当保存CHAR值时，在它们的右边填充空格以达到指定的长度。当检索到CHAR值时，尾部的空格被删除掉。在存储或检索过程中不进行大小写转换。CHAR存储定长数据很方便，CHAR字段上的索引效率级高，比如定义char(10)，那么不论你存储的数据是否达到了10个字节，都要占去10个字节的空间,不足的自动用空格填充。

VARCHAR(M)定义的列的长度为可变长字符串，M取值可以为0~65535之间，(VARCHAR的最大有效长度由最大行大小和使用的字符集确定。整体最大长度是65,532字节）。VARCHAR值保存时只保存需要的字符数，另加一个字节来记录长度(如果列声明的长度超过255，则使用两个字节)。VARCHAR值保存时不进行填充。当值保存和检索时尾部的空格仍保留，符合标准SQL。varchar存储变长数据，但存储效率没有CHAR高。如果一个字段可能的值是不固定长度的，我们只知道它不可能超过10个字符，把它定义为 VARCHAR(10)是最合算的。

CHAR和VARCHAR最大的不同就是一个是固定长度，一个是可变长度。


SHOW  TABLE  STATUS;

即使插入的记录被事务回滚，自增的id也会被占用掉，不会恢复



磁盘结构和工作原理
外观类似留声机
机械硬盘 = 磁头组件 + 磁盘 + 控制电机

磁头组件 = 磁头 + 传动手臂 + 传动轴
磁头组件中最主要的部分是磁头，另外的两个部分可以看作是磁头的辅助装置。传动轴带动传动臂，使磁头到达指定的位置
磁头是硬盘中对盘片进行读写工作的工具，是硬盘中最精密的部位之一。磁头是用线圈缠绕在磁芯上制成的，工作原理则是利用特殊材料的电阻值会随着磁场变化的原理来读写盘片上的数据。硬盘在工作时，磁头通过感应旋转的盘片上磁场的变化来读取数据；通过改变盘片上的磁场来写入数据。为避免磁头和盘片的磨损，在工作状态时，磁头悬浮在高速转动的盘片上方，间隙只有0.1~0.3um，而不是盘片直接接触

磁头的移动是靠磁头驱动组件实现的，硬盘寻道时间的长短与磁头驱动组件关系非常密切

磁头的数量与盘片数量有关。一张单面的磁盘需要一个磁头，如果是双面的磁盘，则需要两个磁头，整个硬盘的磁头的数量就是各个盘片所需要的磁头的数量的总和。磁头可沿盘片的半径方向动作，（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的

磁盘 = 盘片 + 转轴

新买来的硬盘是不能直接使用的，必须对它进行分区进行格式化才能存储数据。经过格式化分区后，逻辑上每个盘片的每一面都会被分为磁道、扇区、柱面这几个虚拟的概念。

磁头靠近主轴接触的表面，即线速度最小的地方，是一个特殊的区域，它不存放任何数据，称为启停区或着陆区（LandingZone），启停区外就是数据区。

磁道
当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，这些圆形轨迹就叫磁道。磁道上的磁道是一组记录密度不同的同心圆。
这些磁道用肉眼是根本看不到的，因为他们仅是盘面上以特殊方式磁化了的一些磁化区，磁盘上的信息便是沿着这样的轨道存放的。相邻磁道之间并不是紧挨着的，这是因为磁化单元相隔太近时磁性会产生相互影响，同时也为磁头的读写带来困难，硬盘的每一个盘面有300～1 024个磁道，新式大容量硬盘每面的磁道数更多。在每个盘面的最外圈，离盘心最远的地方是“0”磁道，向盘心方向依次增长为1磁道，2磁道，等等。硬盘数据的存放就是从最外圈开始。

扇区
分区格式化磁盘时，每个盘片的每一面都会划分很多同心圆的磁道，而且还会将每个同心圆进一步的分割为多个相等的圆弧，这些圆弧就是扇区。为什么要进行扇区的划分呢？因为，读取和写入数据的时候，磁盘会以扇区为单位进行读取和写入数据，即使电脑只需要某个扇区内的几个字节的文件，也必须一次把这几个字节的数据所在的扇区中的全部512字节的数据全部读入内存，然后再进行筛选所需数据，所以为了提高电脑的运行速度，就需要对硬盘进行扇区划分。另外，每个扇区的前后两端都会有一些特定的数据，这些数据用来构成扇区之间的界限标志，磁头通过这些界限标志来识别众多的扇区。

柱面
硬盘通常由一个或多个盘片构成，而且每个面都被划分为数目相等的磁道，并从外缘开始编号（即最边缘的磁道为0磁道，往里依次累加）。如此磁盘中具有相同编号的磁道会形成一个圆柱，此圆柱称为磁盘的柱面。磁盘的柱面数与一个盘面上的磁道数是相等的。不同面上相同磁道编号则组成了一个圆柱面，即所称的柱面(Cylinder)。这里要注意，硬盘数据的读写是按柱面进行，即磁头读写数据时首先在同一柱面内从0磁头开始进行操作，依次向下在同一柱面的不同盘面(即磁头上)进行操作，只有在同一柱面所有的磁头全部读写完毕后磁头才转移到下一柱面，因为选取磁头只需通过电子切换即可，而选取柱面则必须通过机械切换。电子切换比从在机械上磁头向邻近磁道移动快得多。因此，数据的读写按柱面进行，而不按盘面进行。 读写数据都是按照这种方式进行，尽可能提高了硬盘读写效率。

由于硬盘是高精密设备，尘埃是其大敌，所以必须完全密封。

硬盘的工作原理

     现代硬盘寻道都是采用CHS(Cylinder Head Sector)的方式，硬盘读取数据时，读写磁头沿径向移动，移到要读取的扇区所在磁道的上方，这段时间称为寻道时间(seek time)。因读写磁头的起始位置与目标位置之间的距离不同，寻道时间也不同。目前硬盘一般为2到30毫秒，平均约为9毫秒。磁头到达指定磁道后，然后通过盘片的旋转，使得要读取的扇区转到读写磁头的下方，这段时间称为旋转延迟时间(rotational latencytime)。

访盘请求完成过程：

确定磁盘地址（柱面号，磁头号，扇区号），内存地址（源/目）：
       当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。

为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点：
1）首先必须找到柱面，即磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，
2）然后目标扇区旋转到磁头下，即磁盘旋转将目标扇区旋转到磁头下。这个过程耗费的时间叫做旋转时间。

即一次访盘请求（读/写）完成过程由三个动作组成：
1）寻道（时间）：磁头移动定位到指定磁道 
2）旋转延迟（时间）：等待指定扇区从磁头下旋转经过 
3）数据传输（时间）：数据在磁盘与内存之间的实际传输

因此在磁盘上读取扇区数据（一块数据）所需时间：

	Ti/o = tseek + tla + n*twm

其中:
tseek 为寻道时间
tla为旋转时间
twm 为传输时间

局部性原理与磁盘预读

由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：

当一个数据被用到时，其附近的数据也通常会马上被使用。
程序运行期间所需要的数据通常比较集中。
由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。

预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。


磁盘碎片的产生

1.我们从原位置删除文件，重新建个文件重新写上”Hello, World!!”. –这就无意中延长了文件系统的读和写的时间。
2.打碎文件，就是在别的空的地方写上感叹号，也就是”身首异处”–这个点子不错，速度很快，而且方便，但是，这就同时意味着大大的减慢了读取下一个新文件的时间。
这里所说的方法二就像是我们的windows系统的存储方式，每个文件都是紧挨着的，但如果其中某个文件要更改的话，那么就意味着接下来的数据将会被放在磁盘其他的空余的地方。
如果这个文件被删除了，那么就会在系统中留下空格，久而久之，我们的文件系统就会变得支离破碎，碎片就是这么产生的。

我们的数据资料都是以信息的方式存储在盘面的扇区的磁道上,硬盘读取是由摇臂控制磁头从盘面的外侧向内侧进行读写的.所以外侧的数据读取速度会比内侧的数据快很多.其实我们的文件大多数的时候都是破碎的，在文件没有破碎的时候,摇臂只需要寻找1次磁道并由磁头进行读取,只需要1次就可以成功读取;但是如果文件破碎成 11处,那么摇臂要来回寻找11次磁道磁头进行11次读取才能完整的读取这个文件,读取时间相对没有破碎的时候就变得冗长.

由于硬盘生产商和操作系统换算不太一样，硬盘厂家以10进位的办法来换算，而操作系统是以2进位制来换算，所以在换算成M或者G 时，不同的算法结果却不一样；所以我们的硬盘有时标出的是80G，在操作系统下看却少几M

Mysql索引的高效性的原理得益于Mysql索引的实现，B+树，而B+树是B树的一种变种的数据结构，这两种数据结构都是为了磁盘和直接存储设备而设计的。是因为他们能够有效的减少磁盘IO过于频繁带来的磁盘读写效率低下问题

IO是大部分系统性能的瓶颈，网络IO的阻塞和磁盘IO的耗时

							
							寄存器
				内存存储器  高速缓存（CACHE）
							主存
计算机存储系统

				外部存储器  硬盘，光盘

主存存取原理：

从抽象的角度看，主存是由一系列的存储单元组成的矩阵，每个存储单元可以存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。如图展示了一个4 x 4的主存模型。

主存存取过程：

当系统从主存读取数据时，则将地址信号放到地址总线上，主存读到地址信号时，解析信号并定位到指定的存储单元，然后将存储单元的数据放到数据总线上，供其他部件读取。
当系统向主存写数据时，则将地址信号和数据分别放到地址总线和数据总线上，主存读取两个总线的内容，做响应的写操作。






B+Tree索引的性能分析
为什么要用B+树做索引？
哈希结构：如果要进行范围查询（大于4的数据），那这个索引就完全没用了。
二叉树查找树：数据量多的时候，树会很高，需要多次I/O操作。
B+树：所有记录节点存放在叶子节点上，且是顺序存放，由各叶子节点指针进行连接。如果从最左边的叶子节点开始顺序遍历，能得到所有键值的顺序排序。
1.B+树的高度一般为2-4层，所以查找记录时最多只需要2-4次IO，相对二叉平衡树已经大大降低了。
2.范围查找时，能通过叶子节点的指针获取数据。例如查找大于等于3的数据，当在叶子节点中查到3时，通过3的尾指针便能获取所有数据，而不需要再像二叉树一样再获取到3的父节点。

机械硬盘的连续读写性能很好，但随机读写性能很差。

顺序访问：内存访问速度是硬盘访问速度的6~7倍（kafka的特点，以后有机会的话再讲一讲）
随机访问：内存访问速度就要比硬盘访问速度快上10万倍以上

随机读写时，磁头需要不停的移动，时间都浪费在了磁头寻址上。
而在实际的磁盘存储里，由于磁盘碎片的原因，文件是很少顺序存储的，因为这样的维护成本会很高。

聚集索引

							磁盘块0
							| P1 | 3 | P2 | 9 | P3 |


		      磁盘块1	  <----->	  磁盘块2	  <----->	   磁盘块3
		|  0  |  1  |  2  |		|  3  |  4  |  6  |		|  9  |  10   |     |
		| Fla | Sli | Bob |		| Ang | Tom | Rok |		| Jak |  Cra  |     |

P1指向磁盘块1 P2指向磁盘块2 P3指向磁盘块3，

叶子节点存放了整张表的所有行数据。
非叶子节点并不存储行数据，是为了能存储更多索引键，从而降低B+树的高度，进而减少IO次数。
聚集索引的存储在物理上并不是连续的，每个数据页在不同的磁盘块，通过一个双向链表来进行连接。（重要）

查找：假设要查找数据项6
把根节点由磁盘块0加载到内存，发生一次IO，在内存中用二分查找确定6在3和9之间；
通过指针P2的磁盘地址，将磁盘2加载到内存，发生第二次IO，再在内存中进行二分查找找到6，结束。

这里只进行了两次IO，实际上，每个磁盘块大小为4K，3层的B+树可以表示上百万的数据，也就是每次查找只需要3次IO，所以索引对性能的提高将是巨大的。
所以说B+树索引并不能直接找到具体的行，只是找到被查找行所在的页，然后DB通过把整页读入内存，再在内存中查找。

一般情况，用PRIMARY KEY来作为聚集索引。
如果没有定义PRIMARY KEY，将会用第一个UNIQUE且NOT NULL的列来作为聚集索引。
如果表没有合适的UNIQUE索引，会内部根据行ID值生成一个隐藏的聚簇索引GEN_CLUST_INDEX。

B+树非聚集索引
每个表可以有多个辅助索引
通过辅助索引查数据时，先查找辅助索引获得聚集索引的主键，然后通过主键索引来查找完整的行记录。
通过非主键索引比主键索引查找速度要慢一倍。

							磁盘块0
							| P1 | Fla | P2 | Sli | P3 |


		      磁盘块1	  <----->	  磁盘块2	  <----->	   磁盘块3
		|  Ang  |  Bob  |  Cra  |		|  Fla  |  Jak  |  Rok  |		|  Sli  |  Tom   |     |
主键：	|   3   |   2   |   10  |		|   0   |   9   |   6   |		|   1   |   4    |     |

查找：获取NAME=Jake的数据
第一阶段：通过辅助索引查到主键索引的主键

把idx_name索引的根节点由磁盘块0加载到内存，发生一次IO，查找到在P2指针中
根据P2指针的磁盘地址，加载磁盘块2到内存，发生第二次IO，查找到Jake节点以及它的主键索引9

第二阶段：通过主键索引找到完整的行记录

把根节点由磁盘块0加载到内存，发生一次IO，在内存中用二分查找确定9在P3指针中
通过指针P3的磁盘地址，将磁盘3加载到内存，发生第二次IO，再在内存中进行二分查找找到9，以及它的行记录，



我们首先提一个问题， B+树比平衡二叉树在索引数据方面要快么？

大多数人可能认为肯定还是B+树快，毕竟存储同样多的数据，100阶的B+树肯定比平衡二叉树的高度要低的多。但是别忘了B树在一个结点可能需要比较很多次才能找到下一层的结点，但是平衡二叉树只要比较一次就可以向下走一层。所以综合起来，其实两者索引的速度几乎（甚至说就是）是一样的。最简单的道理，一颗4阶B树就是一颗红黑树，比较的次数完全一样。那么我们为什么还要使用B+树呢？这是因为上面说索引速度相当的前提是两者的数据结构都位于内存中，当我们要在磁盘上索引一个记录时，将磁盘中的数据传输到内存中才是花费时间的大头，而在内存中的索引过程所花的时间基本是可以忽略不计的。在磁盘中以B+树的形式组织数据就有着天然的优势。要解释这个道理，我们必须先强调一个概念，主存和磁盘之间的数据交换不是以字节为单位的，而是以n个扇区为单位的（一个扇区有512字节），通常是4KB（8个扇区），8KB（16个扇区），16KB，……64KB为单位的。
假设，我们现在选择4KB作为内存和磁盘之间的传输单位，那么我们在设计B+树的时候，不论是索引结点还是叶子结点都使用4KB作为结点的大小。我们这时不妨再假设一个记录的大小是1KB，那么一个叶子结点可以存4个记录。而对于索引结点（大小也是4KB），由于只需要存key值和相应的指针，所以一个索引结点可能可以存储100~150个分支，我们不妨就取100吧。当然这和B树和B+树的插入、删除图文详解第2节和第3节中的情况不太一样，因为现在索引结点的阶数是100，而叶子结点的阶数是4，两者并不一致，但这并没有什么问题。
我们考虑如上图所示的B+树，下面的B+树有三层，两层是索引结点，最后一层是叶子结点。那么这个三层的B+树最多可以存400万个记录。如果这个B+树存储到硬盘中，我们怎么根据记录的key找到对应的记录呢？首先我们要读取这个B+树的根结点到内存（花费一个IO的时间）然后在内存中进行索引，根据key找到对应的分支，再将这个分支所指向的第二层索引结点读取到内存中（花费第二个IO时间）然后在内存中进行索引，同样根据key找到对应的分支，而这个分支指向的就是叶子结点，我们最后将这个叶子结点读取到内存中（花费的第三个IO时间）判断是否存在这个记录。这样我们只需要通过三次IO时间就从400万个记录中找到了对应的key记录，可以说是非常快了。快速的原因是，索引结点中不存数据，只存键和指针，所以一个索引结点就可以存储大量的分支，而一个索引结点只需要一次IO即可读取到内存中。

我们现在再考虑一个问题，当记录的大小可变时，叶子结点中记录该如何存储？

这个时候有两种极限情况。

1）假设叶子结点的阶数仍然为4，但每个记录仅仅有100个字节，显然当叶子结点中存满4个记录后，叶子结点中仍然有大量的剩余空间。这个时候我们能不能直接向该叶子结点中插入数据，而不必分裂这个叶子结点（分裂指在磁盘中的分裂）？答案是可以，有人一定会说，这不就违反B+树的定义了么？的确违反了，但是B+树之所以定义阶数的目的是为了平衡（或者说增强）每一个分支的索引效率，不过这个优点仅当整个B+树都位于内存时才能体现出来。当B+树存储在磁盘中的情况时，IO效率才是第一要考虑的因素。CPU在某个结点内部多比较几次或少比较几次和IO花费的时间相比就不值得一提了。而不分裂反而能提升B+树的IO效率，因为分裂需要更多的IO次数。综合起来了说就是，文件系统及数据库中的B+树是不考虑阶数这一个概念的，结点（即包括叶子结点，也包括索引结点）中仅遵行一个规则，如果剩余空间够大那么就存入数据，如果剩余空间不够，只能分裂后再存入。

2）如果某条记录太大，即使叶子结点中还剩余一多半的空间但仍然存不下怎么办？这个时候MySql称之为行溢出，简单的解决方式就是把记录存储在溢出页（磁盘的其它空闲地方）中，然后叶子结点中存储的是这个记录的指针。

在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k，而对于我们的InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K。


oracle一般使用堆表，mysql的innodb是索引组织表

堆表以一种显然随机的方式管理，数据插入时时存储位置是随机的，主要是数据库内部块的空闲情况决定，数据会放在最合适的地方，而不是以某种特定顺序来放置。堆组织表的存储速度因为不用考虑排序, 所以存储速度会比较快. 但是要查找符合某个条件的记录, 就必须得读取全部的记录以便筛选.
而这个时候为了加快查询速度, 索引就出现了, 索引是针对少量特定字段的值拿出来进行排序存储, 并记录在表中的位置, 
而因为索引是有序的, 所以就会很容易通过索引查询到具体的记录位置, 然后再根据记录位置直接从表中读取该记录.
同时因为索引的字段较少, 所以索引通常会比其基表小得多.
从上面通过索引访问表记录的方式可以看出, 当要访问的数据量较大时, 通过每一条记录的位置去访问原始记录, 
每一条符合条件的记录都需要经过索引访问后再访问基表这样一个复杂的过程, 这会花费很多时间,
同样, 如果不经过索引而直接查询表, 也可能因为表字段太多, 记录较大的情况下把全部的数据读取进来, 这也会花费很多时间.
那怎么办呢?
这个时候就会想到, 如果表中数据本身就是有序的, 这样查询表的时候就可以快速的找到符合条件的记录位置, 
而很容易判断符合条件记录的位置, 这样只需要读取一小部分数据出来就可以了, 不需要全表记录都读取出来进行判断.
索引表就这样产生了.当然索引表中插入,更新资料的时候可能会因为需要排序而将数据重组, 这时候数据插入或更新速度会比堆组织表慢一些.
如果堆组织表上有索引, 那么对堆组织表的插入也会因为要修改索引而变慢

虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。

第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。
第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。

了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。

最左前缀原理与相关优化
主索引为<emp_no, title, from_date>
情况一：全列匹配。
SELECT * FROM employees.titles WHERE emp_no='10001' AND title='Senior Engineer' AND from_date='1986-06-26'; √
SELECT * FROM employees.titles WHERE from_date='1986-06-26' AND emp_no='10001' AND title='Senior Engineer'; √
当按照索引中所有列进行精确匹配（这里精确匹配指“=”或“IN”匹配）时，索引可以被用到。这里有一点需要注意，理论上索引对顺序是敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引，例如我们将where中的条件顺序颠倒效果是一样的。

情况二：最左前缀匹配。
SELECT * FROM employees.titles WHERE emp_no='10001'; √
当查询条件精确匹配索引的左边连续一个或几个列时，如<emp_no>或<emp_no, title>，所以可以被用到，但是只能用到一部分，即条件所组成的最左前缀。上面的查询从分析结果看用到了PRIMARY索引，但是key_len为4，说明只用到了索引的第一列前缀。

情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供。
SELECT * FROM employees.titles WHERE emp_no='10001' AND from_date='1986-06-26'; √
此时索引使用情况和情况二相同，因为title未提供，所以查询只用到了索引的第一列，而后面的from_date虽然也在索引中，但是由于title不存在而无法和左前缀连接，因此需要对结果进行扫描过滤from_date（这里由于emp_no唯一，所以不存在扫描）。如果想让from_date也使用索引而不是where过滤，可以增加一个辅助索引<emp_no, from_date>，此时上面的查询会使用这个索引。除此之外，还可以使用一种称之为“隔离列”的优化方法，将emp_no与from_date之间的“坑”填上。
 SELECT * FROM employees.titles
WHERE emp_no='10001'
AND title IN ('Senior Engineer', 'Staff', 'Engineer', 'Senior Staff', 'Assistant Engineer', 'Technique Leader', 'Manager')
AND from_date='1986-06-26';

情况四：查询条件没有指定索引第一列。
SELECT * FROM employees.titles WHERE from_date='1986-06-26'; ×

情况五：匹配某列的前缀字符串。 
SELECT * FROM employees.titles WHERE emp_no='10001' AND title LIKE 'Senior%'; √

情况六：范围查询。
SELECT * FROM employees.titles WHERE emp_no < '10010' and title='Senior Engineer'; √
范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。

情况七：查询条件中含有函数或表达式。
SELECT * FROM employees.titles WHERE emp_no='10001' AND left(title, 6)='Senior'; ×
很不幸，如果查询条件中含有函数或表达式，则MySQL不会为这列使用索引（虽然某些在数学意义上可以使用）

InnoDB的主键选择与插入优化(存疑？)

在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。

经常看到有帖子或博客讨论主键选择问题，有人建议使用业务无关的自增主键，有人觉得没有必要，完全可以使用如学号或身份证号这种唯一字段作为主键。不论支持哪种论点，大多数论据都是业务层面的。如果从数据库索引优化角度看，使用InnoDB引擎而不使用自增主键绝对是一个糟糕的主意。

上文讨论过InnoDB的索引实现，InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。

如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。
这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。

如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。





MySQL技术内幕:InnoDB存储引擎

数据库：是物理操作系统文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合，在MYSQL数据库中，数据库文件可以是frm、MYD、MYI、ibd结尾的文件
数据库实例：是一个程序，是位于用户和操作系统之间的一层数据管理软件，用户对数据库数据的任何操作，包括数据库定义、数据查询、数据维护、数据库运行控制等都是在数据库实例下进行的，应用程序只有通过数据库实例才能和数据库打交道，它由后台线程以及一个共享内存区组成，数据库实例才是真正用于操作数据库文件的

数据库是由一个个文件（一般来说都是二进制文件）组成的，要对这些文件执行诸如SELECT、INSERT、UPDATE之类的数据库操作是不能通过简单的操作文件来更改数据库的内容，需要通过数据库实例来完成对数据库的操作

在MYSQL数据库中，实例与数据库的关系通常是一一对应的，即一个实例对应一个数据库，在集群情况下可能存在一个数据库被多个数据实例使用的情况

MYSQL被设计为一个单进程多线程架构的数据库，与SQL Server类似，但与Oracle多进程的架构不同


							  MYSQL体系结构

							连接方（JDBC、ODBC）

						连接池（鉴权、连接限制、内存检查）

	  SQL接口（DML、DDL、存储过程、触发器）   解析器      分析器        缓存	

	        插件式存储引擎（内存、索引、存储管理）（MyISAM、InnoDB）	

	          文件系统                      文件和日志（redo、undo）


InnoDB存储引擎
支持事务，其设计目标主要面向在线事务处理的应用。其特点是行锁设计、支持外键，并支持类似于Oracle的非锁定读，即默认读取操作不会产生锁。从MYSQL5.5.8开始，就是默认的存储引擎
InnoDB通过使用多版本并发控制（MVCC）来获得高并发性，并且实现了SQL标准的4种隔离级别，同时，使用一个被称为next-key locking的策略来避免幻读现象的产生
对于表中数据的存储，InnoDB存储引擎采用了聚集的方式，因此每张表的存储都是按主键的顺序进行存放，如果没有显式地在表定义时指定主键，InnoDB存储引擎会为每一行生成一个6字节的ROWID，并以此作为主键

MYISAM存储引擎
不支持事务、表锁设计，支持全文索引，主要面向一些OLAP数据库应用，此外，它的缓冲池只缓存索引文件，而不缓冲数据文件，这点和大多数的数据库都不同

NDB存储引擎
join操作是在MYSQL数据库层完成的，而不是在存储引擎层完成的，这意味着，复杂的连接操作需要巨大的网络开销，因此查询速度很慢

Memory存储引擎
将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据都将消失，默认使用哈希索引，而不是B+树索引，存储变长字段varchar时是按照定长字段（char）的方式进行的

连接MYSQL操作是一个连接进程和mysql数据库实例（也是一个进程）进行通信，本质上是进程间的通信，常用的进程通信方式有管道、TCP/IP、UNIX域套接字，mysql数据库提供的连接方式从本质上看都是上述提及的进程通信方式

TCP/IP是网络中使用的最多的一种数据库连接方式，这种方式在TCP/IP连接上建立一个基于网络的连接请求，一般情况下客户端在一台服务器，而mysql实例在另一台服务器上，这两台机器通过一个TCP/IP网络连接


InnoDB存储引擎
是事务安全的MYSQL存储引擎，设计上采用了类似于Oracle数据库的架构，通常来说，InnoDB存储引擎是OLTP应用中核心表的首选存储引擎
是第一个完整支持ACID事务的MYSQL存储引擎

InnoDB存储引擎有多个内存块，可以认为这些内存块组成了一个大的内存池，负责如下工作：
维护所有线程需要访问的多个内部数据结构
缓存磁盘上的数据，方便快速地读取，同时在对磁盘文件的数据修改之前在这里缓存
redo log 缓存

后台线程 后台线程 后台线程 后台线程 后台线程

		InnoDB存储引擎内存池

		     数据库文件

后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存是最新的数据，此外将已修改的数据文件刷新到磁盘文件
多个不同的后台线程，负责处理不同的任务

Master Thread
是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新，合并插入缓冲，UNDO页的回收

IO Thread
在InnoDB存储引擎中大量使用了AIO来处理写IO请求，这样可以极大提高数据库的性能。而IO Thread的工作主要是负责这些IO请求的回调处理

Purge Thread
事务被提交后，其所使用的undolog可能不再需要，因此需要PurgeThread来回收已经使用并分配的undo页


内存
缓冲池
InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此可将其视为基于磁盘的数据库系统，由于CPU速度与磁盘速度之间的鸿沟，基于磁盘的数据库系统通常使用缓冲池技术来提高数据库的整体性能
缓冲池简单来说就是一块内存区域，在数据库中进行读取页的操作，首先将从磁盘读到的页存放在缓冲池中，这个过程称为将页FIX在缓冲池中。下一次再读取相同的页时，首先判断该页是否在缓冲池中，若在，称该页在缓冲池中被命中，直接读取该页
对于数据库中页的修改操作，则首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上，但刷新的操作并不是在每次页更新时触发，而是通过一种称为CheckPoint的机制回刷磁盘
缓冲池的大小直接影响着数据库的整体性能

缓冲池：数据页、索引页、插入缓冲、锁信息、自适应哈希索引、数据字典信息
重做日志缓冲

允许有多个缓冲池实例，每个页根据哈希值平均分配到不同缓冲实例中
数据库中的缓冲池是通过LRU（Latest Recent Used最近最少使用）算法来进行管理的，最频繁使用的页在LRU列表的前端，反之在后端，当缓冲池不能存放读取到的页时，将首先释放后端的页
InnoDB缓冲池中页的大小默认为16KB

在LRU列表中的页被修改后，称该页为脏页，即缓冲池中的页和磁盘上的页数据产生了不一致，这时数据库会通过CheckPoint机制将脏页刷新回磁盘，Flush列表中的页即为脏页列表。需要注意的是，脏页即存在于LRU列表中，也存在于Flush列表中，LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘。两者互不影响

重做日志缓冲
InnoDB存储引擎首先将重做日志信息先放入到这个缓冲区，然后按一定频率将其刷新到重做日志文件，重做日志缓冲一般不需要设置得很大，因为一般情况下每一秒会将重做日志缓冲刷新到日志文件，因此用户只需要保证每秒产生的事务量在这个缓冲大小之内即可

在通常情况下，8MB的重做日志缓冲池足以满足绝大部分的应用，重做日志在下列三种情况下会将重做日志缓冲回刷到磁盘的重做日志文件中
1.Master Thread每一秒将重做日志缓冲刷新到重做日志文件
2.每个事务提交时
3.当重做日志缓冲池剩余空间小于1/2时

CheckPoint技术

缓冲池的设计目的为了协调CPU速度与磁盘速度的鸿沟，因此页的操作首先都是在缓冲池中完成的，如果一条DML语句，如update或delete改变了页中的记录，那么此时页是脏的，即缓冲池中的页的版本要比磁盘的新，数据库需要将新版本的页从缓冲池刷新到磁盘
倘若每次一个页发生变化，就将新页的版本刷新到磁盘，那么这个开销是非常大的。若热点数据集中在某几个页中，那么数据库的性能将变得非常差，同时，如果在缓冲池将页的新版本刷新到磁盘时发生了宕机，那么数据就不能恢复了。为了避免发生数据丢失问题，当前事务数据库系统普遍都采用了Write Ahead Log策略，即当事务提交时，先写重做日志，再修改页。当由于发生宕机而导致数据丢失时，通过重做日志来完成数据的恢复，这也是事务ACID中D的要求

思考下面的场景，如果重做日志可以无限地增大，同时缓冲池也足够大，能够缓冲所有数据库的数据，那么是不需要将缓冲池中页的新版本刷新回磁盘。因为当发生宕机时，完全可以通过重做日志来恢复整个数据库系统中的数据到宕机发生时刻，但是这需要两个前提条件：
1缓冲池可以缓存数据库中的所有数据
2重做日志可以无限增大
对于第一点，当前3TB的MYSQL数据库以并不少见，但是3TB的内存却非常少见
对于第二点，重做日志可以无限增大，但是重做日志越大，宕机后数据库的恢复时间就越长，恢复的代价会越来越大
因此CheckPoint检查点技术的目的是解决以下几个问题：
缩短数据库的恢复时间
缓冲池不够用时，将脏页刷新到磁盘
重做日志不可用时，刷新脏页
当数据库发生宕机时，数据库不需要重做所有日志，因为CheckPoint之前的页都已经刷新回磁盘，只需对检查点之后的重做日志进行恢复
当缓冲池不够用时，根据LRU算法会移除最近最少使用的页，若此页为脏页，那么需要强制执行CheckPoint，将脏页数据回刷
重做日志出现不可用的情况是因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是让其无限增大的，

在InnoDB存储引擎中，检查点发生的时间、条件及脏页的选择都非常复杂，其所做的事情无外乎是将缓冲池的数据回刷
检查点分为以下两种
Sharp CheckPoint
Fuzzy CheckPoint
Sharp检查点发生在数据库关闭时将所有的脏页都刷回磁盘
数据库在运行时使用Fuzzy检查点，即只刷新一部分脏页
对于Master Thread中发生的检查点，差不多以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘，这个过程是异步的，用户查询线程不会阻塞
检查点既会发生在LRU列表也会发生在脏页列表

Master Thread工作方式
InnoDB存储引擎的主要工作都是在一个单独的后台线程Master Thread中完成的
Master Thread具有最高级别优先级，其内部由多个循环组成：主循环、后台循环、刷新循环、暂停循环，根据数据库运行状态进行切换
主循环每秒或者每10秒进行一次操作
每秒一次的操作包括：
1.日志缓冲刷新到磁盘，即使这个事务还没有提交
2.合并插入缓冲
3.至多刷新100个InnoDB脏页到磁盘
即时某个事物还没有提交，InnoDB存储引擎仍然每秒会将重做日志缓冲中的内容刷新到重做日志文件
若当前没有用户活动，就会切换到后台循环，后台循环执行以下操作：
1.删除无用的Undo页
2.合并20个插入缓冲
3.跳回主循环

InnoDB关键特性

插入缓冲
两次写
自适应哈希索引
异步IO
刷新邻接页

插入缓冲

insert buffer可能是InnoDB存储引擎关键特性中最令人激动和兴奋的一个功能
插入缓冲和数据页一样，也是物理页的一个组成部分
在InnoDB存储引擎中，主键是行唯一的标识符，通常应用程序中行记录的插入顺序是按照主键递增的顺序进行插入的，因此，插入聚集索引一般是顺序的，不需要磁盘的随机读取
注意：并不是所有的主键插入都是顺序的，若主键类是UUID或者自增主键插入了指定的值，那么可能会导致插入不连续的情况

但是不可恩每张表上只有一个聚集索引，更多情况下，一张表上有多个非聚集的辅助索引，如下：
CREATE TABLE t {
	a INT AUTO_INCREMENT,
	b VARCHAR(30),
	PRIMARY KEY(a),
	key(b)
};
在进行插入操作时，数据页的存放还是按主键a顺序存放的，但是对于非聚集索引叶子节点的插入不再是顺序的了，这时就需要离散地访问非聚集索引页，由于随机读取的存在而导致了插入操作性能下降，当然这并不是这个b字段上索引的错误，而是因为B+树的特性决定了非聚集索引插入的离散性
对此，InnoDB存储引擎开创性地设计了Insert Buffer，对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入，若不在，则先放入到一个Insert Buffer对象中，好似欺骗数据库这个非聚集索引已经插入到叶子节点，而实际并没有，只是存放在另一个位置，然后再以一定的频率和情况进行Insert Buffer和辅助索引页子节点的merge操作，这时通常能够将多个插入合并到一个操作中（因为在一个索引页中），这就大大提高了对于非聚集索引插入的性能

Insert Buffer的使用需要同时满足以下两个条件：
索引是辅助索引
索引不是唯一的
若应用程序进行大量的插入操作，这些都涉及了不唯一的非聚集索引，也就是使用了Insert Buffer，若此时MYSQL数据库发生了宕机，会有大量的插入缓冲并没有合并到实际的非聚集索引中去，因此这时恢复可能需要很长的时间
辅助索引不能是唯一的，因为在插入缓冲时，数据库并不去查找索引页来判断插入记录的唯一性，这个判断比较耗费性能

目前插入缓冲存在的一个问题是，在写密集的情况下，插入缓冲会占用过多的缓冲池内存，默认最大可以占用到1/2的缓冲池内存

change buffer
insert buffer的升级，InnoDB存储引擎可以对DML操作——Insert、Delete、Update都进行缓冲，分别是Insert Buffer、Delete Buffer、Purge Buffer
change buffer适用的对象依然是非唯一的辅助索引

Insert Buffer的内部实现
Insert Buffer的数据结构是一颗B+树，在MYSQL4.1之间的版本中每张表有一棵Insert Buffer B+树，现在的版本中，全局只有一棵，负责对所有的表辅助索引进行Insert Buffer
Insert Buffer是一棵B+树，因此其也由叶子节点和非叶节点组成，非叶节点存放的是查询的search key，其构造如下：
space + marker + offset
space表示待插入记录所在表的表空间id，在InnoDB存储引擎中，每张表有一个唯一的space id，marker用来兼容老版本，offset表示页所在的偏移量

当一个辅助索引要插入到页时，如果这个页不在缓冲池中，那么该索引会先插入到insert buffer中，插入之前，InnoDB存储引擎首先根据上述规则构造一个search key，接下来查询Insert Buffer这棵树，然后再将这条记录插入叶子节点中

因为启用Insert Buffer索引后，辅助索引页中的记录可能被插入到Insert Buffer B+树中，所以为了保证每次Merge Insert Buffer页必须成功，还需要有一个特殊的页用来标记每个辅助索引页的可用空间，这个页的类型为Insert Buffer Bitmap

Merge Insert Buffer
辅助索引从Insert Buffer合并到真正的索引中可能发生在以下几种情况下：
1.辅助索引页被读取到缓冲池时
2.Insert Buffer Bitmap页追踪到该辅助索引页已无可用空间时
3.Master Thread
第一种情况例如在执行Select时，需要检查该辅助索引页是否有记录存放于Insert Buffer B+树中，若有，则将Insert Buffer B+树中该页的记录插入到该辅助索引页中，而且如果该页有多次插入则会被合并为一次操作
Insert Buffer Bitmap页用来追踪每个辅助索引页的可用空间，并至少有1/32页的空间，若检测后发现空间不足1/32，则会进行一次强制合并操作
Master Thread线程每秒或每10秒会进行一次Merge Insert Buffer操作，并且执行merge操作的不止一个页


两次写
double write带给InnoDB存储引擎的是数据页的可靠性

当数据库发生宕机时，可能InnoDB存储引擎正在写入某个页到表中，而这个页只写了一部分，比如16KB的页，只写了前4KB，之后发生了宕机，这种情况被称为部分写失效，这是该页的数据是被损坏的（可能一条记录部分字段是对的，部分字段是错的）
如果写失效，可以通过重做日志进行恢复，但是重做日志记录的是对页的物理操作，如果这个页本身已经发生了损坏，再对其进行重做是没有意义的。这就是说，在应用重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是doublewrite
doublewrite由两部分组成，一部分是内存中的doublewrite buffer，大小为2MB，另一部分是物理磁盘上共享表空间中连续128个页，大小同样为2MB
在对缓冲池的脏页进行刷新时，并不直接写磁盘，而是将脏页先复制到内存中的doublewrite buffer，之后分两次写入物理磁盘
参数skip_innodb_doublewrite可以禁止使用doubleWrite功能，不过，对于需要提供数据高可靠性的服务器，任何时候用户都应该开启doubleWrite功能


自适应哈希索引
哈希的查找时间复杂度为O(1)，B+树的复杂度取决于树的高度，在生产环境中，高度一般为3~4层
InnoDB存储引擎会监控对表上各索引页的查询，如果观察到建立哈希索引可以带来速度提升，则建立哈希索引，称之为自适应哈希索引AHI

AHI是通过缓冲池的B+树页构造而来，因此建立的速度很快，而且不需要对整张表构建哈希索引，InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引

哈希索引只能用来搜索等值的查询，对于其他查找类型，如范围查找，是不能使用哈希索引的

异步IO
用户在发出一个IO请求之后立即再发出另一个IO请求，当全部IO请求发送完毕后，等待所有IO操作的完成

启动、关闭与恢复
参数innodb_fast_shutdown控制数据库正常关闭时的行为 0表示需要完成所有当前任务再关闭 1刷新脏页后就关闭 2写入日志后就关闭
innodb_force_recovery控制数据库启动时的行为 3表示不进行事务的回滚操作


数据库文件
参数文件：告诉MYSQL实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数
日志文件：错误日志，二进制日志、查询日志
socket文件：当用UNIX域套接字方式进行连接时需要的文件
Pid文件：MYSQL实例的进程ID文件
MYSQL表结构文件：用来存放MYSQL表结构定义文件
存储引擎文件：每个存储引擎都会有自己的文件来保存各种数据

MYSQL数据库的参数文件是以文本方式进行存储的，用户可以直接通过一些常用的文本编辑软件进行参数的修改
可以通过命令SHOW VARIABLES查看数据库中的所有参数

慢查询日志文件

可以在MYSQL启动时设一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询日志文件中，通过参数long_query_time来设置，默认值10，代表10秒

打开log_queries_not_using_indexes参数设置，如果运行的SQL语句没有使用索引则记录到慢查询日志文件

物理读是指从磁盘进行IO读取的次数，逻辑读包含所有的读取，不管是磁盘还是缓冲池
通过参数long_query_io将超过指定逻辑IO次数的SQL语句记录到slow log中


查询日志
查询日志记录了所有对mysql数据库请求的信息，无论这些请求是否得到了正确的执行

二进制日志

二进制日志记录了对MYSQL数据库执行更改的所有操作，但是不包括select和show这类操作，因为这类操作对数据本身并没有修改，然而，若操作本身并没有导致数据库发生变化，该操作可能也会写入二进制日志
如果用户想记录SELECT和SHOW操作，那只能使用查询日志，而不是二进制日志
二进制日志主要有以下几种作用：

恢复：某些数据的恢复需要二进制日志

复制：通过复制和执行二进制日志使一台远程的MYSQL（slave）数据库与另一台MYSQL数据库（master）进行实时同步

审计：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入的攻击
审计（事前审计，事后审计）
开启二进制日志的确会影响性能，但是性能的损失十分有限，根据MYSQL官方手册中的测试表明，开启二进制日志会使性能下降1%，但考虑到可以使用复制和point-in-time的恢复，这些性能损失绝对是可以且应该被接受的

在默认情况下，二进制日志并不是在每次写的时候同步到磁盘，当数据库宕机时，可能会有最后一部分数据没有写入文件中，参数sync_binlog=N表示每写缓冲多少次就同步到磁盘，N=1时表示采用同步写磁盘的方式，不过此时会对数据库的IO带来一定的影响

如果当前数据库是复制中的slave角色，则它不会将从master取得并执行的二进制日志写入自己的二进制日志文件中去。如果需要写入，要设置log-slave-update。如果需要搭建主从架构，则必须设置该参数

binlog_format参数十分重要，它影响了记录二进制日志的格式，在MYSQL5.1版本之前，没有这个参数，所有二进制文件的格式都是基于SQL语句级别的，对于复制是有一定要求的，如在主服务器运行rand、uuid等函数，又或者使用触发器等操作，这些都可能会导致主从服务器上表中数据的不一致，另一个影响是，会发现InnoDB存储引擎的默认事务隔离级别是REPEATABLE READ，这其实也是因为二进制日志文件格式的关系，如果使用READ COMMITTED的事务隔离级别（大多数数据库，如oracle，sql server的默认隔离级别），会出现类似丢失更新的现象，从而出现主从数据库上的数据不一致

MYSQL5.1开始引入了binlog_format参数，该参数可设的值有STATEMENT、ROW和MIXED
1.STATEMENT格式和之前的MYSQL版本一样，记录的是SQL语句日志
2.在ROW格式下，记录的是表行的更改情况，如果设置了binlog_format为ROW，可以将InnoDB的事务隔离级别设为READ COMMITED，以获得更好的并发性

二进制日志文件的文件格式为二进制，不能像错误日志文件、慢查询日志文件那样用cat head tail等命令查看，要查看二进制日志文件的内容，必须通过MYSQL提供的工具mysqlbinlog


表结构定义文件
因为mysql插件式存储引擎的体系结构的关系，mysql数据的存储是根据表进行的，每个表都会有与之对应的文件，但不论表采用何种存储引擎，mysql都有一个以fm为后缀名的文件，这个文件记录了该表的表结构定义


InnoDB存储引擎文件
之前介绍的文件都是mysql数据库本身的文件，和存储引擎无关，除了这些文件外，每个表存储引擎还有其自己独有的文件，比如重做日志文件，表空间文件

InnoDB采用将存储的数据按表空间进行存放的设计，对不同的表可以分配单独的表空间，单独的表空间文件仅存储该表的数据、索引、和插入缓冲等信息，其余信息还是存放在默认的表空间中

重做日志文件对于InnoDB存储引擎至关重要，它们记录了对于InnoDB存储引擎的事务日志，当实例失败时，重做日志文件就能派上用场，例如，数据库由于所在主机掉电导致实例失败，InnoDB存储引擎会使用重做日志恢复到掉电前的时刻，以此来保证数据的完整性
重做日志文件的大小设置对于InnoDB存储引擎的性能有着非常大的影响，一方面重做日志文件不能设置得太大，否则在恢复时可能需要很长的时间，但又不能太小，否则会导致一个事务的日志需要多次切换重做日志文件，还会导致频繁地发生async checkpoint，导致性能的抖动

重做日志与二进制日志有什么区别？
二进制日志会记录所有与mysql数据库有关的日志记录，包括各个存储引擎的日志，而InnoDB存储引擎的重做日志只记录有关该存储引擎本身的事务日志。
二进制日志记录的是关于一个事务的具体操作内容，即该日志是逻辑日志，redo log记录的是关于每个页的更改的物理情况
写入的时间也不同，二进制日志文件仅在事务提交前进行写入，即只写磁盘一次，不论这时该事务多大，而在事务进行的过程中，却不断有重做日志被写入
为了保证事务的ACID中的持久性，必须将redo log中innodb_flush_log_at_trx_commit设置为1，每当事务提交时，就必须确保事务都已经写入重做日志文件，那么当数据库因为意外发生宕机时，可以通过重做日志文件恢复，并保证可以恢复已经提交的事务

数据库表结构
表空间（单表空间，共享表空间） -> 段 -> 区 -> 页 -> 行 -> 字段

页
页是InnoDB磁盘管理的最小单位，默认每个页大小为16KB，可以通过参数innodb_page_size将页的大小设置为4K，8K，16K，一旦设置完成不可以再次修改

行
每个页最多允许存放7992行记录
行溢出数据
InnoDB存储引擎可以将一条记录中的某些数据存储在真正的数据页面之外，一般认为BLOB、LOB这类大对象列类型的存储会把数据存放在数据页面之外，但是，这个理解有些偏差，BLOB可以不将数据放在溢出页面，VARCHAR依然可能被存放为行溢出数据

VARCHAR
理论上MYSQL数据库VARCHAR类型可以存放65535字节，实际最多存放65532的长度，对于用户来说VARCHAR（N）中N指的是字符的长度，而文档中说明VARCHAR类型最大支持65535，单位是字节，此外需要注意的是，mysql官方手册中定义的65535长度是指所有VARCHAR列的长度总和，如果列的长度总和超出，依然无法创建
InnoDB存储引擎页的大小为16KB，即16384字节，一般情况下，InnoDB存储引擎的数据都是存放在页类型为B-tree node中，但是当发生行溢出时，数据存放在页类型为Uncompress BLOB页中

InnoDB存储引擎表是索引组织的，即B+tree的结构，这样每个页中至少应该有两条记录，如果页中只能存放下一条记录，那么InnoDB存储引擎会自动将行数据存放到溢出页中

从MYSQL4.1版本开始，CHAR（N）中的N是指字符的长度，而不是之前版本的字节长度

InnoDB数据页由以下7个部分组成
File Header 文件头 存储页的偏移值，上一个下一个页，所属表空间，页类型等
Page Header 页头 所处B+ tree层数，事务Id等
Infimun 和 Supremun Records 最大和最小的两条虚拟记录，在页创建时被建立，在任何情况下都不会被删除
User Records 实际存储数据的空间
Free Space 空闲空间
Page Directory 存放记录的相对位置
File Trailer 为了检测是否已经完整地写入磁盘


约束
关系型数据库系统和文件系统一个不同点是，关系数据库本身能保证存储数据的完整性，不需要应用程序的控制
对于InnoDB而言，提供了以下几种约束
Primary Key
Unique Key
Foreign Key
Not Null















